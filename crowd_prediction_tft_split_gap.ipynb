{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7acafb40",
   "metadata": {},
   "source": [
    "# Beach Crowd Prediction — TFT: Full vs Split-Gap Datasets\n",
    "\n",
    "Compares **NeuralForecast TFT** vs **PyTorch-Forecasting TFT** using daytime-only data\n",
    "with sequential `time_idx`.\n",
    "\n",
    "**Two dataset groups:**\n",
    "1. **Full** — all daytime data as one continuous sequence (no gap)\n",
    "2. **SplitGap** — Early (first 40%) + Late (last 40%) concatenated, skipping the middle 20%\n",
    "\n",
    "This simulates comparing a complete dataset vs having **2022 + 2025 data** with missing years in between.\n",
    "When real 2022 and 2025 data arrives, just replace the Early/Late splits.\n",
    "\n",
    "All plots use **real datetime labels** on the x-axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d0ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:48:28.594313Z",
     "start_time": "2026-02-15T19:48:28.579255Z"
    }
   },
   "outputs": [],
   "source": [
    "CACHE_DIR = \"cache/predictions\"\n",
    "COUNTING_MODEL = \"bayesian_vgg19\"\n",
    "SAVE_DIR = \"models/tft_split_gap\"\n",
    "from pathlib import Path\n",
    "\n",
    "save_dir = Path(SAVE_DIR)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === QUICK TEST FILTERS ===\n",
    "SAMPLE_FRAC = 1\n",
    "MAX_BEACHES = None\n",
    "BEACH_NAMES = None\n",
    "\n",
    "# === GPU ===\n",
    "GPU_NF = 0\n",
    "GPU_PF = 1\n",
    "\n",
    "# === NF TFT PARAMETERS (tuned from sensitivity analysis) ===\n",
    "MAX_STEPS = 1500\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "INPUT_SIZE = 48\n",
    "HORIZON = 12\n",
    "NF_HIDDEN_SIZE = 128\n",
    "NF_N_HEAD = 4\n",
    "NF_SCALER = \"robust\"\n",
    "\n",
    "NIGHT_START = 20\n",
    "NIGHT_END = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0f596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:00.245647Z",
     "start_time": "2026-02-15T19:31:59.195060Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "for pkg in [\"neuralforecast\", \"utilsforecast\"]:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaae9d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:04.431757Z",
     "start_time": "2026-02-15T19:32:01.269688Z"
    }
   },
   "outputs": [],
   "source": [
    "import json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "import torch\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import TFT\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    ACCELERATOR = 'gpu'\n",
    "    NF_DEVICES = [GPU_NF] if n_gpus > 1 else [0]\n",
    "    PF_DEVICES = [GPU_PF] if n_gpus > 1 else [0]\n",
    "    for i in range(n_gpus):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    ACCELERATOR = 'mps'\n",
    "    NF_DEVICES = [0]\n",
    "    PF_DEVICES = [0]\n",
    "else:\n",
    "    ACCELERATOR = 'cpu'\n",
    "    NF_DEVICES = [0]\n",
    "    PF_DEVICES = [0]\n",
    "\n",
    "print(f\"Accelerator: {ACCELERATOR} | NF GPU: {NF_DEVICES} | PF GPU: {PF_DEVICES}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13539953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:04.439994Z",
     "start_time": "2026-02-15T19:32:04.437637Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred, max_count):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rel_mae = (mae / max_count) * 100 if max_count > 0 else 0\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'RelMAE': rel_mae}\n",
    "\n",
    "def eval_per_beach(df, y_pred, beach_col='unique_id'):\n",
    "    results = []\n",
    "    for b in df[beach_col].unique():\n",
    "        mask = df[beach_col] == b\n",
    "        if mask.sum() < 3:\n",
    "            continue\n",
    "        y_true = df.loc[mask, 'y'].values if 'y' in df.columns else df.loc[mask, 'count'].values\n",
    "        y_p = y_pred[mask.values] if hasattr(mask, 'values') else y_pred[mask]\n",
    "        max_count = y_true.max()\n",
    "        m = calc_metrics(y_true, y_p, max_count)\n",
    "        m['camera'] = b\n",
    "        m['max_count'] = max_count\n",
    "        m['n'] = mask.sum()\n",
    "        results.append(m)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980944f",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f5950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:30.684434Z",
     "start_time": "2026-02-15T19:32:04.449371Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cache(cache_dir, model):\n",
    "    cache_path = Path(cache_dir) / model\n",
    "    records = []\n",
    "    for jf in cache_path.rglob(\"*.json\"):\n",
    "        try:\n",
    "            with open(jf) as f:\n",
    "                r = json.load(f)\n",
    "            if 'error' not in r:\n",
    "                records.append(r)\n",
    "        except: pass\n",
    "    \n",
    "    rows = []\n",
    "    for r in records:\n",
    "        row = {\n",
    "            'beach': r.get('beach') or r.get('beach_folder'),\n",
    "            'beach_folder': r.get('beach_folder'),\n",
    "            'datetime': r.get('datetime'),\n",
    "            'count': r.get('count')\n",
    "        }\n",
    "        for k, v in r.get('weather', {}).items():\n",
    "            row[k] = v\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_raw = load_cache(CACHE_DIR, COUNTING_MODEL)\n",
    "print(f\"Loaded: {len(df_raw)} rows, {df_raw['beach'].nunique()} beaches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26af23f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:30.849127Z",
     "start_time": "2026-02-15T19:32:30.707990Z"
    }
   },
   "outputs": [],
   "source": [
    "EXCLUDE = ['livecampro/001', 'livecampro/011', 'livecampro/018', 'livecampro/021',\n",
    "    'livecampro/030', 'livecampro/039', 'livecampro/070', 'MultimediaTres/PortAndratx',\n",
    "    'SeeTheWorld/mallorca_pancam', 'skyline/es-pujols']\n",
    "EXCLUDE_PREFIX = ['ibred', 'ClubNauticSoller', 'Guenthoer', 'youtube']\n",
    "\n",
    "before = len(df_raw)\n",
    "df_raw = df_raw[~df_raw['beach_folder'].isin(EXCLUDE)]\n",
    "for p in EXCLUDE_PREFIX:\n",
    "    df_raw = df_raw[~df_raw['beach_folder'].str.startswith(p, na=False)]\n",
    "print(f\"Filtered: {before} -> {len(df_raw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53950688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:30.873709Z",
     "start_time": "2026-02-15T19:32:30.859161Z"
    }
   },
   "outputs": [],
   "source": [
    "if SAMPLE_FRAC < 1.0:\n",
    "    df_raw = df_raw.sample(frac=SAMPLE_FRAC, random_state=42).sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "if BEACH_NAMES:\n",
    "    df_raw = df_raw[df_raw['beach_folder'].isin(BEACH_NAMES)].reset_index(drop=True)\n",
    "    print(f\"Filtered to {len(BEACH_NAMES)} specific beaches: {BEACH_NAMES}\")\n",
    "elif MAX_BEACHES:\n",
    "    top = df_raw['beach_folder'].value_counts().head(MAX_BEACHES).index.tolist()\n",
    "    df_raw = df_raw[df_raw['beach_folder'].isin(top)].reset_index(drop=True)\n",
    "    print(f\"Top {MAX_BEACHES} beaches by data: {top}\")\n",
    "\n",
    "print(f\"Final: {len(df_raw)} rows, {df_raw['beach_folder'].nunique()} beaches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c17ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:30.919834Z",
     "start_time": "2026-02-15T19:32:30.878984Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)\n",
    "df['is_night'] = ((df['hour'] >= NIGHT_START) | (df['hour'] <= NIGHT_END)).astype(int)\n",
    "\n",
    "WEATHER_COLS = [c for c in df.columns if c.startswith('ae_') or c.startswith('om_')]\n",
    "TEMPORAL_COLS = ['hour', 'day_of_week', 'month', 'is_weekend', 'is_summer', 'is_night']\n",
    "ALL_FEATURES = WEATHER_COLS + TEMPORAL_COLS\n",
    "\n",
    "df = df.dropna(subset=ALL_FEATURES + ['count']).reset_index(drop=True)\n",
    "good = df.groupby('beach')['count'].max()\n",
    "good = good[good > 20].index.tolist()\n",
    "df = df[df['beach'].isin(good)].reset_index(drop=True)\n",
    "\n",
    "print(f\"After cleaning: {len(df)} rows, {len(good)} beaches\")\n",
    "print(f\"Features: {len(ALL_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722d9e8e",
   "metadata": {},
   "source": [
    "## Daytime Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6bbbea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:30.938171Z",
     "start_time": "2026-02-15T19:32:30.927228Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_daytime = df[df['is_night'] == 0].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"Daytime dataset: {len(ds_daytime)} rows, {ds_daytime['beach'].nunique()} beaches\")\n",
    "print(f\"Hours range: {ds_daytime['hour'].min()} to {ds_daytime['hour'].max()}\")\n",
    "print(f\"Date range: {ds_daytime['datetime'].min().date()} to {ds_daytime['datetime'].max().date()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32b2ba6",
   "metadata": {},
   "source": [
    "### Data Overview Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76560f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:31.475820Z",
     "start_time": "2026-02-15T19:32:30.943189Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. Rows per beach\n",
    "beach_counts = ds_daytime.groupby('beach_folder').size().sort_values(ascending=True)\n",
    "colors = ['coral' if b in (BEACH_NAMES or []) else 'steelblue' for b in beach_counts.index]\n",
    "axes[0,0].barh(range(len(beach_counts)), beach_counts.values, color=colors if BEACH_NAMES else 'steelblue', alpha=0.8)\n",
    "axes[0,0].set_yticks(range(len(beach_counts)))\n",
    "axes[0,0].set_yticklabels([b.split('/')[-1][:20] for b in beach_counts.index], fontsize=7)\n",
    "axes[0,0].set_xlabel('Rows')\n",
    "axes[0,0].set_title('Daytime Rows per Beach')\n",
    "\n",
    "# 2. Hourly distribution\n",
    "hourly = ds_daytime.groupby('hour')['count'].agg(['mean', 'std'])\n",
    "axes[0,1].bar(hourly.index, hourly['mean'], yerr=hourly['std'], color='steelblue', alpha=0.7, capsize=2)\n",
    "axes[0,1].set_xlabel('Hour')\n",
    "axes[0,1].set_ylabel('Avg Count')\n",
    "axes[0,1].set_title('Average Crowd by Hour')\n",
    "\n",
    "# 3. Daily pattern over time (one line per beach)\n",
    "daily = ds_daytime.groupby([ds_daytime['datetime'].dt.date, 'beach_folder'])['count'].max().reset_index()\n",
    "daily.columns = ['date', 'beach', 'max_count']\n",
    "daily['date'] = pd.to_datetime(daily['date'])\n",
    "for beach in daily['beach'].unique():\n",
    "    sub = daily[daily['beach'] == beach]\n",
    "    axes[1,0].plot(sub['date'], sub['max_count'], linewidth=0.5, alpha=0.5)\n",
    "axes[1,0].set_xlabel('Date')\n",
    "axes[1,0].set_ylabel('Daily Max Count')\n",
    "axes[1,0].set_title('Daily Peak Occupancy (all beaches)')\n",
    "axes[1,0].tick_params(axis='x', rotation=30)\n",
    "\n",
    "# 4. Count distribution\n",
    "axes[1,1].hist(ds_daytime['count'], bins=80, color='steelblue', alpha=0.7, edgecolor='white')\n",
    "axes[1,1].axvline(ds_daytime['count'].mean(), color='red', linestyle='--', label=f\"Mean={ds_daytime['count'].mean():.1f}\")\n",
    "axes[1,1].axvline(ds_daytime['count'].median(), color='orange', linestyle='--', label=f\"Median={ds_daytime['count'].median():.1f}\")\n",
    "axes[1,1].set_xlabel('Count')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title('Count Distribution (Daytime)')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.suptitle(f\"Data Overview — {ds_daytime['beach_folder'].nunique()} beaches, {len(ds_daytime)} rows\", fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir / 'data_overview.png', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c0b53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:31.692339Z",
     "start_time": "2026-02-15T19:32:31.483011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Weather feature correlations with count\n",
    "feat_corr = ds_daytime[['count'] + WEATHER_COLS[:15]].corr()['count'].drop('count').sort_values()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "axes[0].barh(range(len(feat_corr)), feat_corr.values, color=['coral' if v < 0 else 'steelblue' for v in feat_corr.values], alpha=0.8)\n",
    "axes[0].set_yticks(range(len(feat_corr)))\n",
    "axes[0].set_yticklabels(feat_corr.index, fontsize=7)\n",
    "axes[0].set_xlabel('Correlation with Count')\n",
    "axes[0].set_title('Weather Features vs Crowd Count')\n",
    "axes[0].axvline(0, color='black', linewidth=0.5)\n",
    "\n",
    "# Temporal feature importance\n",
    "temp_corr = ds_daytime[['count'] + TEMPORAL_COLS].corr()['count'].drop('count').sort_values()\n",
    "axes[1].barh(range(len(temp_corr)), temp_corr.values, color=['coral' if v < 0 else 'green' for v in temp_corr.values], alpha=0.8)\n",
    "axes[1].set_yticks(range(len(temp_corr)))\n",
    "axes[1].set_yticklabels(temp_corr.index, fontsize=9)\n",
    "axes[1].set_xlabel('Correlation with Count')\n",
    "axes[1].set_title('Temporal Features vs Crowd Count')\n",
    "axes[1].axvline(0, color='black', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir / 'feature_correlations.png', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4781fe",
   "metadata": {},
   "source": [
    "## Build Two Dataset Groups\n",
    "\n",
    "1. **Full** — entire daytime dataset, continuous\n",
    "2. **SplitGap** — Early (first 40%) + Late (last 40%) concatenated into one sequence, gap removed\n",
    "\n",
    "Train/Val/Test splits are handled internally by NeuralForecast (`cross_validation` with `n_windows` + `h`)\n",
    "and PyTorch-Forecasting (`TimeSeriesDataSet`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f9388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:31.722747Z",
     "start_time": "2026-02-15T19:32:31.697820Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = ds_daytime.sort_values(['beach_folder', 'datetime']).reset_index(drop=True)\n",
    "n = len(ds)\n",
    "\n",
    "full_data = ds.copy()\n",
    "\n",
    "early = ds.iloc[:int(n * 0.4)].copy()\n",
    "late = ds.iloc[int(n * 0.6):].copy()\n",
    "gap_start = ds.iloc[int(n * 0.4)]['datetime']\n",
    "gap_end = ds.iloc[int(n * 0.6)]['datetime']\n",
    "splitgap_data = pd.concat([early, late]).sort_values(['beach_folder', 'datetime']).reset_index(drop=True)\n",
    "\n",
    "dataset_groups = {\n",
    "    'Full': {'name': 'Full', 'data': full_data},\n",
    "    'SplitGap': {'name': 'SplitGap', 'data': splitgap_data},\n",
    "}\n",
    "\n",
    "for ds_info in dataset_groups.values():\n",
    "    name = ds_info['name']\n",
    "    d = ds_info['data']\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Date range: {d['datetime'].min().date()} to {d['datetime'].max().date()}\")\n",
    "    print(f\"  Total: {len(d)} | Beaches: {d['beach_folder'].nunique()}\")\n",
    "\n",
    "print(f\"\\nSplitGap removed: {gap_start.date()} to {gap_end.date()} ({len(ds) - len(splitgap_data)} rows)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245df589",
   "metadata": {},
   "source": [
    "### Dataset Overview Visualization\n",
    "\n",
    "Distribution comparison between Full and SplitGap datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949bdee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:32.050596Z",
     "start_time": "2026-02-15T19:32:31.727399Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Legend for splits\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Stats comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "for i, (name, ds_info) in enumerate(dataset_groups.items()):\n",
    "    d = ds_info['data']\n",
    "    color = 'steelblue' if name == 'Full' else 'coral'\n",
    "\n",
    "    axes[0].hist(d['count'], bins=50, alpha=0.5, label=name, color=color, edgecolor='white')\n",
    "    axes[1].hist(d['hour'], bins=range(25), alpha=0.5, label=name, color=color, edgecolor='white')\n",
    "\n",
    "    monthly = d.groupby(d['datetime'].dt.month)['count'].mean()\n",
    "    axes[2].plot(monthly.index, monthly.values, 'o-', label=name, color=color)\n",
    "\n",
    "axes[0].set_xlabel('Count'); axes[0].set_title('Count Distribution'); axes[0].legend()\n",
    "axes[1].set_xlabel('Hour'); axes[1].set_title('Hour Distribution'); axes[1].legend()\n",
    "axes[2].set_xlabel('Month'); axes[2].set_title('Avg Count by Month'); axes[2].legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir / 'dataset_comparison.png', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ac9dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:32.718395Z",
     "start_time": "2026-02-15T19:32:32.055569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preview of actual NF cross_validation windows\n",
    "# NF uses the last (n_windows * h) steps as test, everything before is train\n",
    "\n",
    "fig, axes = plt.subplots(len(dataset_groups), 1, figsize=(16, 4 * len(dataset_groups)), sharex=True)\n",
    "if len(dataset_groups) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, (ds_name, ds_info) in zip(axes, dataset_groups.items()):\n",
    "    d = ds_info['data'].sort_values(['beach_folder', 'datetime']).reset_index(drop=True)\n",
    "    series_len = d.groupby('beach_folder').size()\n",
    "    min_len = series_len.min()\n",
    "\n",
    "    h = min(HORIZON, min_len // 4)\n",
    "    n_windows = max(1, (min_len // 4) // h)\n",
    "    if n_windows > 3:\n",
    "        n_windows = 3\n",
    "    test_steps = n_windows * h\n",
    "\n",
    "    for uid in d['beach_folder'].unique():\n",
    "        grp = d[d['beach_folder'] == uid].sort_values('datetime')\n",
    "        n_pts = len(grp)\n",
    "        cutoff = n_pts - test_steps\n",
    "        train_part = grp.iloc[:cutoff]\n",
    "        test_part = grp.iloc[cutoff:]\n",
    "        ax.scatter(train_part['datetime'], train_part['count'], s=1, alpha=0.3, c='tab:blue')\n",
    "        ax.scatter(test_part['datetime'], test_part['count'], s=1, alpha=0.3, c='tab:red')\n",
    "\n",
    "    if ds_name == 'SplitGap':\n",
    "        ax.axvspan(gap_start, gap_end, alpha=0.12, color='red', label=f'Gap ({gap_start.date()}\\u2192{gap_end.date()})')\n",
    "\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'{ds_name} \\u2014 NF Actual Split: h={h}, n_windows={n_windows}, test_steps={test_steps}')\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_els = [\n",
    "        Line2D([0],[0], marker='o', color='w', markerfacecolor='tab:blue', markersize=6, label='Train'),\n",
    "        Line2D([0],[0], marker='o', color='w', markerfacecolor='tab:red', markersize=6, label=f'Test (last {test_steps} steps)'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_els, loc='upper right', fontsize=8)\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.suptitle('Actual NF cross_validation Windows (Train vs Test)', fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir / 'data_split_distribution.png', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6bb082",
   "metadata": {},
   "source": [
    "## Prepare NF Data with Sequential `time_idx`\n",
    "\n",
    "Each beach gets a continuous integer index (no gaps even in SplitGap).\n",
    "A `time_idx → datetime` mapping is stored for plotting.\n",
    "Test/val sizes are derived from `h` and `n_windows` to match NF's actual logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af5a5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:32:33.043606Z",
     "start_time": "2026-02-15T19:32:32.728552Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_nf_with_mapping(ds_info):\n",
    "    all_data = ds_info['data'].sort_values(['beach_folder', 'datetime']).reset_index(drop=True)\n",
    "    all_data['unique_id'] = all_data['beach_folder']\n",
    "    all_data['y'] = all_data['count']\n",
    "    all_data['ds'] = all_data.groupby('unique_id').cumcount()\n",
    "\n",
    "    dt_map = all_data.set_index(['unique_id', 'ds'])['datetime'].to_dict()\n",
    "\n",
    "    series_len = all_data.groupby('unique_id').size()\n",
    "    min_len = series_len.min()\n",
    "    h = min(HORIZON, min_len // 4)\n",
    "    n_windows = max(1, (min_len // 4) // h)\n",
    "    if n_windows > 3:\n",
    "        n_windows = 3\n",
    "    test_size = n_windows * h\n",
    "    val_size = h  # one horizon window for internal validation\n",
    "\n",
    "    cols = ['unique_id', 'ds', 'y'] + [c for c in ALL_FEATURES if c in all_data.columns]\n",
    "    nf_df = all_data[cols].copy()\n",
    "\n",
    "    for col in nf_df.select_dtypes(include=[np.number]).columns:\n",
    "        if col != 'ds':\n",
    "            nf_df[col] = nf_df.groupby('unique_id')[col].transform(\n",
    "                lambda x: x.interpolate(method='linear').ffill().bfill()\n",
    "            )\n",
    "\n",
    "    return nf_df, dt_map, h, n_windows, val_size\n",
    "\n",
    "nf_data = {}\n",
    "for name, ds_info in dataset_groups.items():\n",
    "    nf_df, dt_map, h, n_win, val_sz = prepare_nf_with_mapping(ds_info)\n",
    "    nf_data[name] = {'nf_df': nf_df, 'dt_map': dt_map, 'h': h, 'n_windows': n_win, 'val_size': val_sz}\n",
    "    print(f\"{name}: {len(nf_df)} rows | h={h} | n_windows={n_win} | val_size={val_sz}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbc043",
   "metadata": {},
   "source": [
    "## NeuralForecast TFT — Full vs SplitGap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d23aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:35:07.141164Z",
     "start_time": "2026-02-15T19:32:33.048694Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning.pytorch\").setLevel(logging.WARNING)\n",
    "\n",
    "all_results = []\n",
    "all_cv_details = []\n",
    "\n",
    "def run_nf_tft(name, nf_df, dt_map, h, n_windows, val_size):\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"NF_TFT \\u2014 {name} | h={h} | n_windows={n_windows} | val_size={val_size} | series={nf_df['unique_id'].nunique()}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        model = TFT(\n",
    "            h=h, input_size=INPUT_SIZE,\n",
    "            hidden_size=NF_HIDDEN_SIZE, n_head=NF_N_HEAD,\n",
    "            max_steps=MAX_STEPS, early_stop_patience_steps=10,\n",
    "            learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE,\n",
    "            scaler_type=NF_SCALER, random_seed=42,\n",
    "            accelerator=ACCELERATOR, devices=NF_DEVICES,\n",
    "            loss=MAE(), hist_exog_list=ALL_FEATURES, val_check_steps=50,\n",
    "            enable_progress_bar=False,\n",
    "        )\n",
    "        nf = NeuralForecast(models=[model], freq=1)\n",
    "        cv = nf.cross_validation(df=nf_df, val_size=val_size, n_windows=n_windows, step_size=h)\n",
    "        elapsed = time.time() - t0\n",
    "\n",
    "        pred_col = [c for c in cv.columns if c not in ['unique_id', 'ds', 'cutoff', 'y']][0]\n",
    "        cv['pred'] = np.clip(cv[pred_col].values, 0, None)\n",
    "        cv['datetime'] = cv.apply(lambda r: dt_map.get((r['unique_id'], int(r['ds'])), None), axis=1)\n",
    "\n",
    "        m = calc_metrics(cv['y'].values, cv['pred'].values, cv['y'].max())\n",
    "\n",
    "        beach_res = []\n",
    "        for b in cv['unique_id'].unique():\n",
    "            bm = cv[cv['unique_id'] == b]\n",
    "            if len(bm) < 3:\n",
    "                continue\n",
    "            bmetrics = calc_metrics(bm['y'].values, bm['pred'].values, bm['y'].max())\n",
    "            bmetrics['beach'] = b\n",
    "            beach_res.append(bmetrics)\n",
    "        beach_df = pd.DataFrame(beach_res)\n",
    "        avg_rel = beach_df['RelMAE'].mean() if len(beach_df) > 0 else m['RelMAE']\n",
    "\n",
    "        all_results.append({\n",
    "            'Model': 'NF_TFT', 'Dataset': name, 'MAE': m['MAE'], 'RMSE': m['RMSE'],\n",
    "            'R2': m['R2'], 'AvgRelMAE': avg_rel, 'Time': elapsed,\n",
    "        })\n",
    "        all_cv_details.append({\n",
    "            'name': name, 'model': 'NF_TFT', 'merged': cv, 'beach_df': beach_df,\n",
    "        })\n",
    "        print(f\"  {elapsed:.0f}s | MAE={m['MAE']:.1f} | RelMAE={avg_rel:.1f}% | R2={m['R2']:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: {e}\")\n",
    "        import traceback; traceback.print_exc()\n",
    "\n",
    "for name, d in nf_data.items():\n",
    "    run_nf_tft(name, d['nf_df'], d['dt_map'], d['h'], d['n_windows'], d['val_size'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe07140",
   "metadata": {},
   "source": [
    "## NF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_results)\n",
    "save_dir = Path(SAVE_DIR)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_df.to_csv(save_dir / 'nf_results.csv', index=False)\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4d6a4",
   "metadata": {},
   "source": [
    "### Predictions vs Actual — NF TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for detail in all_cv_details:\n",
    "    merged = detail['merged']\n",
    "    name = detail['name']\n",
    "\n",
    "    beaches = merged.groupby('unique_id').size().nlargest(4).index.tolist()\n",
    "    fig, axes = plt.subplots(len(beaches), 1, figsize=(16, 4 * len(beaches)), sharex=False)\n",
    "    if len(beaches) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, beach in zip(axes, beaches):\n",
    "        sub = merged[merged['unique_id'] == beach].sort_values('ds')\n",
    "        x = pd.to_datetime(sub['datetime']) if sub['datetime'].notna().all() else sub['ds']\n",
    "        ax.plot(x, sub['y'], label='Actual', color='steelblue', linewidth=1.2)\n",
    "        ax.plot(x, sub['pred'], label='Predicted', color='coral', linewidth=1.2, alpha=0.85)\n",
    "        ax.fill_between(x, sub['y'], sub['pred'], alpha=0.15, color='red')\n",
    "\n",
    "        mae_v = np.abs(sub['y'] - sub['pred']).mean()\n",
    "        r2_v = r2_score(sub['y'], sub['pred']) if len(sub) > 3 else 0\n",
    "        ax.set_title(f'{beach.split(\"/\")[-1]} | MAE={mae_v:.1f} | R\\u00b2={r2_v:.3f}', fontsize=10, loc='left')\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "        ax.set_ylabel('Count')\n",
    "        if hasattr(x.iloc[0], 'strftime'):\n",
    "            ax.tick_params(axis='x', rotation=30)\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d %H:%M'))\n",
    "\n",
    "    axes[-1].set_xlabel('Date')\n",
    "    plt.suptitle(f\"NF_TFT Predictions — {name}\", fontsize=13, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / f'nf_pred_{name}.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Zoomed view: best day\n",
    "    for beach in beaches[:1]:\n",
    "        sub = merged[merged['unique_id'] == beach].copy()\n",
    "        if sub['datetime'].notna().all():\n",
    "            sub['date'] = pd.to_datetime(sub['datetime']).dt.date\n",
    "            best_date = sub.groupby('date').apply(lambda g: np.abs(g['y'] - g['pred']).mean()).idxmin()\n",
    "            worst_date = sub.groupby('date').apply(lambda g: np.abs(g['y'] - g['pred']).mean()).idxmax()\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "            for ax, date, label in [(axes[0], best_date, 'Best Day'), (axes[1], worst_date, 'Worst Day')]:\n",
    "                day = sub[sub['date'] == date].sort_values('datetime')\n",
    "                x = pd.to_datetime(day['datetime'])\n",
    "                ax.plot(x, day['y'], 'o-', color='steelblue', label='Actual', markersize=4)\n",
    "                ax.plot(x, day['pred'], 's-', color='coral', label='Predicted', markersize=4, alpha=0.8)\n",
    "                ax.fill_between(x, day['y'], day['pred'], alpha=0.15, color='red')\n",
    "                mae_d = np.abs(day['y'] - day['pred']).mean()\n",
    "                ax.set_title(f'{label}: {date} | MAE={mae_d:.1f}', fontsize=10)\n",
    "                ax.legend(fontsize=8)\n",
    "                ax.set_ylabel('Count')\n",
    "                ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "                ax.tick_params(axis='x', rotation=30)\n",
    "\n",
    "            plt.suptitle(f\"NF_TFT {name} — {beach.split('/')[-1]} | Best vs Worst Day\", fontsize=12, y=1.02)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_dir / f'nf_zoom_{name}.png', dpi=150)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b05ff",
   "metadata": {},
   "source": [
    "### Error Analysis — NF TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e32ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for detail in all_cv_details:\n",
    "    merged = detail['merged']\n",
    "    name = detail['name']\n",
    "\n",
    "    errors = merged['y'].values - merged['pred'].values\n",
    "    abs_err = np.abs(errors)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "    # 1. Error distribution\n",
    "    axes[0,0].hist(errors, bins=60, color='steelblue', alpha=0.7, edgecolor='white')\n",
    "    axes[0,0].axvline(0, color='red', linestyle='--')\n",
    "    axes[0,0].axvline(errors.mean(), color='orange', linestyle='--', label=f'Bias={errors.mean():.1f}')\n",
    "    axes[0,0].set_title('Error Distribution')\n",
    "    axes[0,0].set_xlabel('Error (Actual - Predicted)')\n",
    "    axes[0,0].legend()\n",
    "\n",
    "    # 2. Scatter actual vs predicted\n",
    "    axes[0,1].scatter(merged['y'], merged['pred'], s=3, alpha=0.3, color='steelblue')\n",
    "    mx = max(merged['y'].max(), merged['pred'].max())\n",
    "    axes[0,1].plot([0, mx], [0, mx], 'r--', linewidth=1, label='Perfect')\n",
    "    axes[0,1].set_xlabel('Actual'); axes[0,1].set_ylabel('Predicted')\n",
    "    axes[0,1].set_title('Actual vs Predicted')\n",
    "    axes[0,1].legend()\n",
    "\n",
    "    # 3. MAE by hour\n",
    "    if 'datetime' in merged.columns and merged['datetime'].notna().any():\n",
    "        mt = merged.dropna(subset=['datetime']).copy()\n",
    "        mt['hour'] = pd.to_datetime(mt['datetime']).dt.hour\n",
    "        mt['abs_err'] = np.abs(mt['y'] - mt['pred'])\n",
    "        hourly = mt.groupby('hour')['abs_err'].mean()\n",
    "        axes[0,2].bar(hourly.index, hourly.values, color='coral', alpha=0.7)\n",
    "        axes[0,2].set_xlabel('Hour'); axes[0,2].set_ylabel('MAE')\n",
    "        axes[0,2].set_title('MAE by Hour of Day')\n",
    "\n",
    "    # 4. MAE by day of week\n",
    "    if 'datetime' in merged.columns and merged['datetime'].notna().any():\n",
    "        mt['dow'] = pd.to_datetime(mt['datetime']).dt.dayofweek\n",
    "        dow_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "        dow_mae = mt.groupby('dow')['abs_err'].mean()\n",
    "        axes[1,0].bar([dow_names[i] for i in dow_mae.index], dow_mae.values, color='green', alpha=0.7)\n",
    "        axes[1,0].set_ylabel('MAE')\n",
    "        axes[1,0].set_title('MAE by Day of Week')\n",
    "\n",
    "    # 5. Per-beach RelMAE\n",
    "    bdf = detail['beach_df'].sort_values('RelMAE') if len(detail['beach_df']) > 0 else pd.DataFrame()\n",
    "    if len(bdf) > 0:\n",
    "        colors = ['green' if v < 25 else 'steelblue' if v < 50 else 'coral' for v in bdf['RelMAE']]\n",
    "        axes[1,1].barh(range(len(bdf)), bdf['RelMAE'], color=colors, alpha=0.8)\n",
    "        axes[1,1].set_yticks(range(len(bdf)))\n",
    "        axes[1,1].set_yticklabels([b.split('/')[-1][:20] for b in bdf['beach']], fontsize=7)\n",
    "        axes[1,1].set_xlabel('RelMAE (%)')\n",
    "        axes[1,1].set_title('Per-Beach Relative MAE')\n",
    "        axes[1,1].invert_yaxis()\n",
    "\n",
    "    # 6. Residuals over time\n",
    "    if 'datetime' in merged.columns and merged['datetime'].notna().any():\n",
    "        mt_sorted = mt.sort_values('datetime')\n",
    "        axes[1,2].scatter(pd.to_datetime(mt_sorted['datetime']), mt_sorted['y'] - mt_sorted['pred'],\n",
    "                          s=1, alpha=0.3, color='steelblue')\n",
    "        axes[1,2].axhline(0, color='red', linestyle='--', linewidth=0.8)\n",
    "        axes[1,2].set_xlabel('Date'); axes[1,2].set_ylabel('Residual')\n",
    "        axes[1,2].set_title('Residuals Over Time')\n",
    "        axes[1,2].tick_params(axis='x', rotation=30)\n",
    "\n",
    "    plt.suptitle(f'NF_TFT Error Analysis \\u2014 {name}', fontsize=14, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / f'nf_error_{name}.png', dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da641eb1",
   "metadata": {},
   "source": [
    "---\n",
    "## PyTorch-Forecasting TFT (Daytime Only)\n",
    "\n",
    "Same split-gap datasets (Early / Late), using integer `time_idx`.\n",
    "Plots use datetime labels from the mapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "for pkg in [\"pytorch-forecasting\", \"pytorch_optimizer\"]:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE as PF_MAE, QuantileLoss\n",
    "\n",
    "# === PF TFT PARAMETERS (tuned from sensitivity analysis) ===\n",
    "PF_MAX_ENCODER = 96      # was 48, sensitivity: 96 -> R2=0.90\n",
    "PF_MAX_PREDICTION = 24\n",
    "PF_BATCH_SIZE = 64\n",
    "PF_MAX_EPOCHS = 80\n",
    "PF_HIDDEN_SIZE = 32      # was 64, sensitivity: 32 -> R2=0.87\n",
    "PF_LR = 0.005            # was 0.01, sensitivity: 0.005 -> R2=0.84\n",
    "PF_DROPOUT = 0.2         # was 0.1, sensitivity: 0.2 -> R2=0.89\n",
    "\n",
    "PF_KNOWN = ['hour', 'day_of_week', 'month', 'is_weekend', 'is_summer']\n",
    "PF_UNKNOWN = ['count'] + WEATHER_COLS\n",
    "\n",
    "pf_results = []\n",
    "pf_cv_details = []\n",
    "print(\"PF ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pf_tft(name, ds_info):\n",
    "    data = ds_info['data'].sort_values(['beach_folder', 'datetime']).reset_index(drop=True)\n",
    "    data['group_id'] = data['beach_folder'].astype(str)\n",
    "    data['time_idx'] = data.groupby('group_id').cumcount()\n",
    "\n",
    "    dt_map = data.set_index(['group_id', 'time_idx'])['datetime'].to_dict()\n",
    "\n",
    "    known_reals = [c for c in PF_KNOWN if c in data.columns]\n",
    "    unknown_reals = [c for c in PF_UNKNOWN if c in data.columns]\n",
    "\n",
    "    series_len = data.groupby('group_id').size()\n",
    "    min_len = series_len.min()\n",
    "    h = min(PF_MAX_PREDICTION, min_len // 4)\n",
    "\n",
    "    if h < 4 or min_len < PF_MAX_ENCODER + h + 10:\n",
    "        print(f\"  {name}: series too short ({min_len}), skipping\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"PF_TFT \\u2014 {name} | h={h} | series={data['group_id'].nunique()}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    try:\n",
    "        training_ds = TimeSeriesDataSet(\n",
    "            data[data['time_idx'] <= data.groupby('group_id')['time_idx'].transform('max') - h],\n",
    "            time_idx='time_idx', target='count', group_ids=['group_id'],\n",
    "            min_encoder_length=PF_MAX_ENCODER // 2, max_encoder_length=PF_MAX_ENCODER,\n",
    "            min_prediction_length=1, max_prediction_length=h,\n",
    "            time_varying_known_reals=['time_idx'] + known_reals,\n",
    "            time_varying_unknown_reals=unknown_reals,\n",
    "            target_normalizer=GroupNormalizer(groups=['group_id'], transformation='softplus'),\n",
    "            add_relative_time_idx=True, add_target_scales=True, add_encoder_length=True,\n",
    "        )\n",
    "        test_ds = TimeSeriesDataSet.from_dataset(training_ds, data, predict=True, stop_randomization=True)\n",
    "        train_dl = training_ds.to_dataloader(train=True, batch_size=PF_BATCH_SIZE, num_workers=0)\n",
    "        test_dl = test_ds.to_dataloader(train=False, batch_size=PF_BATCH_SIZE * 4, num_workers=0)\n",
    "\n",
    "        t0 = time.time()\n",
    "        early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, mode='min')\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=PF_MAX_EPOCHS, accelerator='auto', devices=PF_DEVICES,\n",
    "            gradient_clip_val=0.1, callbacks=[early_stop],\n",
    "            enable_model_summary=False, enable_progress_bar=False,\n",
    "        )\n",
    "        tft = TemporalFusionTransformer.from_dataset(\n",
    "            training_ds, learning_rate=PF_LR,\n",
    "            hidden_size=PF_HIDDEN_SIZE, attention_head_size=4,\n",
    "            dropout=PF_DROPOUT, hidden_continuous_size=PF_HIDDEN_SIZE,\n",
    "            loss=QuantileLoss(), optimizer='adam', reduce_on_plateau_patience=4,\n",
    "        )\n",
    "        trainer.fit(tft, train_dataloaders=train_dl, val_dataloaders=test_dl)\n",
    "        elapsed = time.time() - t0\n",
    "\n",
    "        raw_preds = tft.predict(test_dl, mode=\"raw\", return_x=True, trainer_kwargs=dict(accelerator='cpu'))\n",
    "        predictions = tft.predict(test_dl, return_y=True, trainer_kwargs=dict(accelerator='cpu'))\n",
    "\n",
    "        y_pred_raw = predictions.output.cpu().numpy()\n",
    "        if y_pred_raw.ndim == 3:\n",
    "            y_pred_raw = y_pred_raw.mean(axis=-1)\n",
    "        y_pred = np.clip(y_pred_raw.flatten(), 0, None)\n",
    "        y_true = predictions.y[0].cpu().numpy().flatten()\n",
    "        m = calc_metrics(y_true, y_pred, y_true.max())\n",
    "\n",
    "        pf_results.append({\n",
    "            'Model': 'PF_TFT', 'Dataset': name, 'MAE': m['MAE'], 'RMSE': m['RMSE'],\n",
    "            'R2': m['R2'], 'AvgRelMAE': m['RelMAE'], 'Time': elapsed,\n",
    "        })\n",
    "        pf_cv_details.append({\n",
    "            'name': name, 'model': 'PF_TFT', 'y_true': y_true, 'y_pred': y_pred,\n",
    "            'raw_predictions': raw_preds, 'tft_model': tft, 'test_dl': test_dl,\n",
    "            'dt_map': dt_map,\n",
    "        })\n",
    "        print(f\"  {elapsed:.0f}s | MAE={m['MAE']:.1f} | RelMAE={m['RelMAE']:.1f}% | R2={m['R2']:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: {e}\")\n",
    "        import traceback; traceback.print_exc()\n",
    "\n",
    "for name, ds_info in dataset_groups.items():\n",
    "    run_pf_tft(name, ds_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cb21d",
   "metadata": {},
   "source": [
    "### PF Results & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_results_df = pd.DataFrame(pf_results)\n",
    "if len(pf_results_df) > 0:\n",
    "    print(pf_results_df.to_string(index=False))\n",
    "    pf_results_df.to_csv(save_dir / 'pf_results.csv', index=False)\n",
    "\n",
    "for detail in pf_cv_details:\n",
    "    name = detail['name']\n",
    "\n",
    "    # Built-in TFT plot (encoder context + attention)\n",
    "    if 'raw_predictions' in detail and detail['raw_predictions'] is not None:\n",
    "        try:\n",
    "            raw = detail['raw_predictions']\n",
    "            tft_model = detail['tft_model']\n",
    "            n_plots = min(4, raw.output['prediction'].shape[0])\n",
    "            fig, axes = plt.subplots(n_plots, 1, figsize=(16, 3.5 * n_plots))\n",
    "            if n_plots == 1:\n",
    "                axes = [axes]\n",
    "            for idx in range(n_plots):\n",
    "                tft_model.plot_prediction(raw.x, raw.output, idx=idx, ax=axes[idx], add_loss_to_title=True)\n",
    "            plt.suptitle(f\"PF_TFT Attention + Prediction \\u2014 {name}\", fontsize=13, y=1.01)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_dir / f'pf_attention_{name}.png', dpi=150)\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"  plot_prediction failed: {e}\")\n",
    "\n",
    "    # Actual vs Predicted\n",
    "    y_true = detail['y_true']\n",
    "    y_pred = detail['y_pred']\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # Scatter\n",
    "    axes[0].scatter(y_true, y_pred, s=3, alpha=0.3, color='coral')\n",
    "    mx = max(y_true.max(), y_pred.max())\n",
    "    axes[0].plot([0, mx], [0, mx], 'r--', linewidth=1)\n",
    "    axes[0].set_xlabel('Actual'); axes[0].set_ylabel('Predicted')\n",
    "    axes[0].set_title(f'PF_TFT {name}: Actual vs Predicted')\n",
    "\n",
    "    # Error distribution\n",
    "    errors = y_true - y_pred\n",
    "    axes[1].hist(errors, bins=60, color='coral', alpha=0.7, edgecolor='white')\n",
    "    axes[1].axvline(0, color='red', linestyle='--')\n",
    "    axes[1].axvline(errors.mean(), color='orange', linestyle='--', label=f'Bias={errors.mean():.1f}')\n",
    "    axes[1].set_title(f'PF_TFT {name}: Error Distribution')\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Time series overlay\n",
    "    n_show = min(200, len(y_true))\n",
    "    axes[2].plot(range(n_show), y_true[:n_show], color='steelblue', linewidth=1, label='Actual')\n",
    "    axes[2].plot(range(n_show), y_pred[:n_show], color='coral', linewidth=1, alpha=0.8, label='Predicted')\n",
    "    axes[2].fill_between(range(n_show), y_true[:n_show], y_pred[:n_show], alpha=0.15, color='red')\n",
    "    axes[2].set_title(f'PF_TFT {name}: First {n_show} Predictions')\n",
    "    axes[2].set_xlabel('Step'); axes[2].set_ylabel('Count')\n",
    "    axes[2].legend(fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / f'pf_error_{name}.png', dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efcc7e0",
   "metadata": {},
   "source": [
    "---\n",
    "## Full Comparison: NF vs PF × Full vs SplitGap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85758d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([results_df, pf_results_df], ignore_index=True) if len(pf_results_df) > 0 else results_df.copy()\n",
    "combined.to_csv(save_dir / 'combined_results.csv', index=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"NF_TFT vs PF_TFT — Full vs SplitGap\")\n",
    "print(\"=\" * 70)\n",
    "print(combined[['Model', 'Dataset', 'MAE', 'R2', 'AvgRelMAE', 'Time']].to_string(index=False))\n",
    "\n",
    "if len(combined) >= 2:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # 1. MAE comparison\n",
    "    pivot_mae = combined.pivot_table(index='Dataset', columns='Model', values='MAE')\n",
    "    pivot_mae.plot(kind='bar', ax=axes[0,0], width=0.6, color=['steelblue', 'coral'])\n",
    "    axes[0,0].set_ylabel('MAE'); axes[0,0].set_title('MAE (lower=better)')\n",
    "    axes[0,0].tick_params(axis='x', rotation=0)\n",
    "    for container in axes[0,0].containers:\n",
    "        axes[0,0].bar_label(container, fmt='%.1f', fontsize=8)\n",
    "\n",
    "    # 2. R2 comparison\n",
    "    pivot_r2 = combined.pivot_table(index='Dataset', columns='Model', values='R2')\n",
    "    pivot_r2.plot(kind='bar', ax=axes[0,1], width=0.6, color=['steelblue', 'coral'])\n",
    "    axes[0,1].set_ylabel('R\\u00b2'); axes[0,1].set_title('R\\u00b2 (higher=better)')\n",
    "    axes[0,1].tick_params(axis='x', rotation=0)\n",
    "    for container in axes[0,1].containers:\n",
    "        axes[0,1].bar_label(container, fmt='%.3f', fontsize=8)\n",
    "\n",
    "    # 3. RelMAE comparison\n",
    "    pivot_rel = combined.pivot_table(index='Dataset', columns='Model', values='AvgRelMAE')\n",
    "    pivot_rel.plot(kind='bar', ax=axes[1,0], width=0.6, color=['steelblue', 'coral'])\n",
    "    axes[1,0].set_ylabel('AvgRelMAE (%)'); axes[1,0].set_title('Relative MAE (lower=better)')\n",
    "    axes[1,0].tick_params(axis='x', rotation=0)\n",
    "    for container in axes[1,0].containers:\n",
    "        axes[1,0].bar_label(container, fmt='%.1f%%', fontsize=8)\n",
    "\n",
    "    # 4. Training time\n",
    "    pivot_time = combined.pivot_table(index='Dataset', columns='Model', values='Time')\n",
    "    pivot_time.plot(kind='bar', ax=axes[1,1], width=0.6, color=['steelblue', 'coral'])\n",
    "    axes[1,1].set_ylabel('Seconds'); axes[1,1].set_title('Training Time')\n",
    "    axes[1,1].tick_params(axis='x', rotation=0)\n",
    "    for container in axes[1,1].containers:\n",
    "        axes[1,1].bar_label(container, fmt='%.0fs', fontsize=8)\n",
    "\n",
    "    plt.suptitle('Full Dataset vs SplitGap — NF_TFT vs PF_TFT', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'nf_vs_pf_comparison.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Radar chart (if 4 models)\n",
    "    if len(combined) == 4:\n",
    "        from matplotlib.patches import FancyBboxPatch\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        models = combined.apply(lambda r: f\"{r['Model']}\\n{r['Dataset']}\", axis=1)\n",
    "        metrics = ['MAE', 'AvgRelMAE']\n",
    "        x = np.arange(len(models))\n",
    "        w = 0.35\n",
    "        bars1 = ax.bar(x - w/2, combined['MAE'], w, label='MAE', color='steelblue', alpha=0.8)\n",
    "        bars2 = ax.bar(x + w/2, combined['AvgRelMAE'], w, label='RelMAE (%)', color='coral', alpha=0.8)\n",
    "        ax.set_xticks(x); ax.set_xticklabels(models, fontsize=9)\n",
    "        ax.legend(); ax.set_title('All Models Side by Side')\n",
    "        ax.bar_label(bars1, fmt='%.1f', fontsize=7)\n",
    "        ax.bar_label(bars2, fmt='%.1f%%', fontsize=7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_dir / 'all_models_comparison.png', dpi=150)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f877e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for _, row in combined.iterrows():\n",
    "    print(f\"  {row['Model']:8s} | {row['Dataset']:10s} | MAE={row['MAE']:.1f} | \"\n",
    "          f\"RelMAE={row['AvgRelMAE']:.1f}% | R2={row['R2']:.3f}\")\n",
    "\n",
    "overall = combined.loc[combined['AvgRelMAE'].idxmin()]\n",
    "print(f\"\\nBEST: {overall['Model']} on {overall['Dataset']} | RelMAE={overall['AvgRelMAE']:.1f}%\")\n",
    "\n",
    "print(\"\\nKey insights:\")\n",
    "print(\"  - Full = complete daytime dataset (continuous)\")\n",
    "print(\"  - SplitGap = Early (40%) + Late (40%), middle 20% removed\")\n",
    "print(\"  - If Full >> SplitGap -> the gap hurts, model needs continuous data\")\n",
    "print(\"  - If Full \\u2248 SplitGap -> model handles disconnected periods well\")\n",
    "print(\"  - Ready for real 2022 + 2025 data: replace early/late in cell 13\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
