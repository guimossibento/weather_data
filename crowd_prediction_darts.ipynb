{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7acafb40",
   "metadata": {},
   "source": [
    "# Beach Crowd Prediction — Darts: LSTM & TFT + Optuna Optimization\n",
    "\n",
    "This notebook compares models across **five dataset strategies**:\n",
    "1. **Daytime only** — remove night hours (8PM–6AM)\n",
    "2. **Full 24h** — keep all data including noisy night counts\n",
    "3. **Night = 0** — keep 24h but replace night counts with 0\n",
    "4. **NightQ1** — replace night counts with Q1 of daytime counts per beach\n",
    "5. **NightMin** — replace night counts with min daytime count per beach\n",
    "\n",
    "Models tested:\n",
    "- **Sklearn baselines**: Lasso, RandomForest, XGBoost, LightGBM, CatBoost\n",
    "- **Darts Deep Learning**: LSTM (via BlockRNNModel), TFT (TFTModel)\n",
    "- **Optuna-optimized**: XGBoost, LightGBM, CatBoost, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = \"cache/predictions\"\n",
    "COUNTING_MODEL = \"bayesian_vgg19\"\n",
    "SAVE_DIR = \"models/darts_comparison\"\n",
    "\n",
    "SAMPLE_FRAC = 1.0\n",
    "MAX_BEACHES = None\n",
    "\n",
    "# Darts model parameters\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "INPUT_CHUNK_LENGTH = 24\n",
    "OUTPUT_CHUNK_LENGTH = 12\n",
    "\n",
    "NIGHT_START = 20\n",
    "NIGHT_END = 6\n",
    "\n",
    "OPTUNA_TRIALS = 30\n",
    "OPTUNA_TIMEOUT = 300\n",
    "\n",
    "RUN_SKLEARN = True\n",
    "RUN_DARTS = True\n",
    "RUN_OPTUNA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "pkgs = [\"darts\", \"xgboost\", \"lightgbm\", \"catboost\", \"optuna\", \"utilsforecast\"]\n",
    "for pkg in pkgs:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])\n",
    "print(\"Packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaae9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except: HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    HAS_LGBM = True\n",
    "except: HAS_LGBM = False\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "    HAS_CATBOOST = True\n",
    "except: HAS_CATBOOST = False\n",
    "\n",
    "try:\n",
    "    from darts import TimeSeries\n",
    "    from darts.models import TFTModel, BlockRNNModel\n",
    "    from darts.dataprocessing.transformers import Scaler\n",
    "    from darts.utils.likelihood_models import QuantileRegression\n",
    "    HAS_DARTS = True\n",
    "except Exception as e:\n",
    "    print(f\"Darts error: {e}\")\n",
    "    HAS_DARTS = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    ACCELERATOR = 'gpu'\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    ACCELERATOR = 'mps'\n",
    "else:\n",
    "    ACCELERATOR = 'cpu'\n",
    "\n",
    "PL_TRAINER_KWARGS = {\"accelerator\": ACCELERATOR, \"devices\": 1}\n",
    "\n",
    "print(f\"Accelerator: {ACCELERATOR}\")\n",
    "print(f\"XGB: {HAS_XGB}, LGBM: {HAS_LGBM}, CatBoost: {HAS_CATBOOST}, Darts: {HAS_DARTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13539953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred, max_count):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rel_mae = (mae / max_count) * 100 if max_count > 0 else 0\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'RelMAE': rel_mae}\n",
    "\n",
    "def eval_per_beach(df, y_pred, beach_col='unique_id'):\n",
    "    results = []\n",
    "    for b in df[beach_col].unique():\n",
    "        mask = df[beach_col] == b\n",
    "        if mask.sum() < 3:\n",
    "            continue\n",
    "        y_true = df.loc[mask, 'y'].values if 'y' in df.columns else df.loc[mask, 'count'].values\n",
    "        y_p = y_pred[mask.values] if hasattr(mask, 'values') else y_pred[mask]\n",
    "        max_count = y_true.max()\n",
    "        m = calc_metrics(y_true, y_p, max_count)\n",
    "        m['camera'] = b\n",
    "        m['max_count'] = max_count\n",
    "        m['n'] = mask.sum()\n",
    "        results.append(m)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980944f",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache(cache_dir, model):\n",
    "    cache_path = Path(cache_dir) / model\n",
    "    records = []\n",
    "    for jf in cache_path.rglob(\"*.json\"):\n",
    "        try:\n",
    "            with open(jf) as f:\n",
    "                r = json.load(f)\n",
    "            if 'error' not in r:\n",
    "                records.append(r)\n",
    "        except: pass\n",
    "    \n",
    "    rows = []\n",
    "    for r in records:\n",
    "        row = {\n",
    "            'beach': r.get('beach') or r.get('beach_folder'),\n",
    "            'beach_folder': r.get('beach_folder'),\n",
    "            'datetime': r.get('datetime'),\n",
    "            'count': r.get('count')\n",
    "        }\n",
    "        for k, v in r.get('weather', {}).items():\n",
    "            row[k] = v\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_raw = load_cache(CACHE_DIR, COUNTING_MODEL)\n",
    "print(f\"Loaded: {len(df_raw)} rows, {df_raw['beach'].nunique()} beaches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26af23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDE = ['livecampro/001', 'livecampro/011', 'livecampro/018', 'livecampro/021',\n",
    "    'livecampro/030', 'livecampro/039', 'livecampro/070', 'MultimediaTres/PortAndratx',\n",
    "    'SeeTheWorld/mallorca_pancam', 'skyline/es-pujols']\n",
    "EXCLUDE_PREFIX = ['ibred', 'ClubNauticSoller', 'Guenthoer', 'youtube']\n",
    "\n",
    "before = len(df_raw)\n",
    "df_raw = df_raw[~df_raw['beach_folder'].isin(EXCLUDE)]\n",
    "for p in EXCLUDE_PREFIX:\n",
    "    df_raw = df_raw[~df_raw['beach_folder'].str.startswith(p, na=False)]\n",
    "print(f\"Filtered: {before} -> {len(df_raw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53950688",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_FRAC < 1.0:\n",
    "    df_raw = df_raw.sample(frac=SAMPLE_FRAC, random_state=42).sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "if MAX_BEACHES:\n",
    "    top = df_raw['beach'].value_counts().head(MAX_BEACHES).index.tolist()\n",
    "    df_raw = df_raw[df_raw['beach'].isin(top)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Final: {len(df_raw)} rows, {df_raw['beach'].nunique()} beaches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)\n",
    "df['is_night'] = ((df['hour'] >= NIGHT_START) | (df['hour'] <= NIGHT_END)).astype(int)\n",
    "\n",
    "WEATHER_COLS = [c for c in df.columns if c.startswith('ae_') or c.startswith('om_')]\n",
    "TEMPORAL_COLS = ['hour', 'day_of_week', 'month', 'is_weekend', 'is_summer', 'is_night']\n",
    "ALL_FEATURES = WEATHER_COLS + TEMPORAL_COLS\n",
    "\n",
    "df = df.dropna(subset=ALL_FEATURES + ['count']).reset_index(drop=True)\n",
    "good = df.groupby('beach')['count'].max()\n",
    "good = good[good > 20].index.tolist()\n",
    "df = df[df['beach'].isin(good)].reset_index(drop=True)\n",
    "\n",
    "print(f\"After cleaning: {len(df)} rows, {len(good)} beaches\")\n",
    "print(f\"Features: {len(ALL_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff774dc",
   "metadata": {},
   "source": [
    "## Create Dataset Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ff4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_daytime = df[df['is_night'] == 0].copy().reset_index(drop=True)\n",
    "ds_full24h = df.copy()\n",
    "ds_night0 = df.copy()\n",
    "ds_night0.loc[ds_night0['is_night'] == 1, 'count'] = 0.0\n",
    "\n",
    "ds_nightq1 = df.copy()\n",
    "q1_per_beach = ds_nightq1[ds_nightq1['is_night'] == 0].groupby('beach')['count'].quantile(0.25)\n",
    "ds_nightq1.loc[ds_nightq1['is_night'] == 1, 'count'] = ds_nightq1.loc[ds_nightq1['is_night'] == 1, 'beach'].map(q1_per_beach).fillna(0)\n",
    "\n",
    "ds_nightmin = df.copy()\n",
    "min_per_beach = ds_nightmin[ds_nightmin['is_night'] == 0].groupby('beach')['count'].min()\n",
    "ds_nightmin.loc[ds_nightmin['is_night'] == 1, 'count'] = ds_nightmin.loc[ds_nightmin['is_night'] == 1, 'beach'].map(min_per_beach).fillna(0)\n",
    "\n",
    "datasets = {'Daytime': ds_daytime, 'Full24h': ds_full24h, 'Night0': ds_night0, 'NightQ1': ds_nightq1, 'NightMin': ds_nightmin}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, d in datasets.items():\n",
    "    night_rows = d[d['is_night'] == 1] if 'is_night' in d.columns else pd.DataFrame()\n",
    "    day_rows = d[d['is_night'] == 0] if 'is_night' in d.columns else d\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Total rows: {len(d)}, Beaches: {d['beach'].nunique()}\")\n",
    "    print(f\"  Night: {len(night_rows)} ({len(night_rows)/len(d)*100:.1f}%), Day: {len(day_rows)} ({len(day_rows)/len(d)*100:.1f}%)\")\n",
    "    print(f\"  Count mean: {d['count'].mean():.1f}, max: {d['count'].max():.1f}, zeros: {(d['count'] == 0).sum()} ({(d['count'] == 0).sum()/len(d)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccdb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, train_frac=0.7, val_frac=0.15):\n",
    "    n = len(df)\n",
    "    t1 = int(n * train_frac)\n",
    "    t2 = int(n * (train_frac + val_frac))\n",
    "    return df.iloc[:t1], df.iloc[t1:t2], df.iloc[t2:]\n",
    "\n",
    "splits = {}\n",
    "for name, d in datasets.items():\n",
    "    train, val, test = split_data(d)\n",
    "    splits[name] = {'train': train, 'val': val, 'test': test}\n",
    "    print(f\"{name}: train={len(train)}, val={len(val)}, test={len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beafbbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(datasets), 1, figsize=(14, 3 * len(datasets)), sharex=True)\n",
    "\n",
    "for ax, (ds_name, s) in zip(axes, splits.items()):\n",
    "    train_df = s['train']\n",
    "    val_df = s['val']\n",
    "    test_df = s['test']\n",
    "    \n",
    "    ax.scatter(train_df['datetime'], train_df['count'], s=1, alpha=0.3, c='tab:blue', label='Train')\n",
    "    ax.scatter(val_df['datetime'], val_df['count'], s=1, alpha=0.3, c='tab:orange', label='Validation')\n",
    "    ax.scatter(test_df['datetime'], test_df['count'], s=1, alpha=0.3, c='tab:red', label='Test')\n",
    "    \n",
    "    split1 = val_df['datetime'].min()\n",
    "    split2 = test_df['datetime'].min()\n",
    "    ax.axvline(split1, color='black', linestyle='--', linewidth=1.5, label=f'Train/Val split ({split1.date()})')\n",
    "    ax.axvline(split2, color='black', linestyle='-', linewidth=1.5, label=f'Val/Test split ({split2.date()})')\n",
    "    \n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'{ds_name} — Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}')\n",
    "    ax.legend(loc='upper right', markerscale=5, fontsize=8)\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.suptitle('Train / Validation / Test Split per Dataset', fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8455f",
   "metadata": {},
   "source": [
    "## Prepare Datasets with Gap Filling and Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8efd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsforecast.preprocessing import fill_gaps\n",
    "\n",
    "def to_nf_format(df, id_col='beach_folder'):\n",
    "    cols = ['datetime', id_col, 'count'] + ALL_FEATURES\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    nf_df = df[cols].copy()\n",
    "    nf_df = nf_df.rename(columns={'datetime': 'ds', id_col: 'unique_id', 'count': 'y'})\n",
    "    return nf_df\n",
    "\n",
    "def prepare_dataset_with_filled_gaps(train_df, test_df, freq='h'):\n",
    "    nf_train = to_nf_format(train_df)\n",
    "    nf_test = to_nf_format(test_df)\n",
    "    \n",
    "    nf_train = nf_train.groupby(['unique_id', 'ds']).mean(numeric_only=True).reset_index()\n",
    "    nf_test = nf_test.groupby(['unique_id', 'ds']).mean(numeric_only=True).reset_index()\n",
    "    \n",
    "    nf_train = fill_gaps(nf_train, freq=freq)\n",
    "    nf_test = fill_gaps(nf_test, freq=freq)\n",
    "    \n",
    "    numeric_cols = nf_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numeric_cols:\n",
    "        nf_train[col] = nf_train.groupby('unique_id')[col].transform(\n",
    "            lambda x: x.interpolate(method='linear').ffill().bfill()\n",
    "        )\n",
    "        nf_test[col] = nf_test.groupby('unique_id')[col].transform(\n",
    "            lambda x: x.interpolate(method='linear').ffill().bfill()\n",
    "        )\n",
    "    \n",
    "    common_ids = set(nf_train['unique_id'].unique()) & set(nf_test['unique_id'].unique())\n",
    "    nf_train = nf_train[nf_train['unique_id'].isin(common_ids)].reset_index(drop=True)\n",
    "    nf_test = nf_test[nf_test['unique_id'].isin(common_ids)].reset_index(drop=True)\n",
    "    \n",
    "    return nf_train, nf_test, list(common_ids)\n",
    "\n",
    "prepared_data = {}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PREPARING DATASETS WITH FILLED GAPS + INTERPOLATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for ds_name in datasets.keys():\n",
    "    print(f\"\\nProcessing: {ds_name}\")\n",
    "    s = splits[ds_name]\n",
    "    train_val = pd.concat([s['train'], s['val']])\n",
    "    \n",
    "    nf_train, nf_test, series_ids = prepare_dataset_with_filled_gaps(train_val, s['test'])\n",
    "    \n",
    "    prepared_data[ds_name] = {\n",
    "        'train': nf_train,\n",
    "        'test': nf_test,\n",
    "        'series_ids': series_ids,\n",
    "        'n_series': len(series_ids),\n",
    "    }\n",
    "    \n",
    "    print(f\"  Train: {len(nf_train)}, Test: {len(nf_test)}, Series: {len(series_ids)}\")\n",
    "    print(f\"  NaN check - train: {nf_train['y'].isna().sum()}, test: {nf_test['y'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bee08a",
   "metadata": {},
   "source": [
    "## Sklearn Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "all_beach_results = []\n",
    "\n",
    "if RUN_SKLEARN:\n",
    "    for ds_name in datasets.keys():\n",
    "        data = prepared_data[ds_name]\n",
    "        train_df = data['train']\n",
    "        test_df = data['test']\n",
    "        \n",
    "        feature_cols = [c for c in train_df.columns if c not in ['unique_id', 'ds', 'y']]\n",
    "        \n",
    "        X_train = train_df[feature_cols]\n",
    "        y_train = train_df['y']\n",
    "        X_test = test_df[feature_cols]\n",
    "        y_test = test_df['y']\n",
    "        \n",
    "        sklearn_models = {\n",
    "            'Lasso': Lasso(alpha=0.1),\n",
    "            'RandomForest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
    "        }\n",
    "        if HAS_XGB:\n",
    "            sklearn_models['XGBoost'] = XGBRegressor(n_estimators=200, max_depth=6, random_state=42, n_jobs=-1, verbosity=0)\n",
    "        if HAS_LGBM:\n",
    "            sklearn_models['LightGBM'] = LGBMRegressor(n_estimators=200, max_depth=6, random_state=42, n_jobs=-1, verbose=-1)\n",
    "        if HAS_CATBOOST:\n",
    "            sklearn_models['CatBoost'] = CatBoostRegressor(n_estimators=200, max_depth=6, random_state=42, verbose=0)\n",
    "        \n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"SKLEARN - {ds_name}\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "        print(f\"Train: {len(X_train)}, Test: {len(X_test)}, Features: {len(feature_cols)}\")\n",
    "        \n",
    "        for name, model in sklearn_models.items():\n",
    "            t0 = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = np.clip(model.predict(X_test), 0, None)\n",
    "            elapsed = time.time() - t0\n",
    "            \n",
    "            m = calc_metrics(y_test.values, y_pred, y_test.max())\n",
    "            \n",
    "            eval_df = test_df[['unique_id', 'y']].copy()\n",
    "            eval_df['count'] = eval_df['y']\n",
    "            eval_df['beach'] = eval_df['unique_id']\n",
    "            beach_df = eval_per_beach(eval_df, y_pred, 'beach')\n",
    "            beach_df['model'] = name\n",
    "            beach_df['dataset'] = ds_name\n",
    "            all_beach_results.append(beach_df)\n",
    "            \n",
    "            avg_rel = beach_df['RelMAE'].mean()\n",
    "            all_results.append({\n",
    "                'Model': name, 'Dataset': ds_name, 'Type': 'Sklearn',\n",
    "                'MAE': m['MAE'], 'RMSE': m['RMSE'], 'R2': m['R2'],\n",
    "                'AvgRelMAE': avg_rel, 'Time': elapsed\n",
    "            })\n",
    "            print(f\"  {name:15s} | {elapsed:5.1f}s | MAE={m['MAE']:.1f} | RelMAE={avg_rel:.1f}% | R2={m['R2']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa0ca0",
   "metadata": {},
   "source": [
    "## Darts Deep Learning Models: LSTM & TFT\n",
    "\n",
    "| Model | Implementation | Strengths | Best For |\n",
    "|-------|---------------|-----------|----------|\n",
    "| **LSTM** | BlockRNNModel | Classic baseline, sequential patterns | Time-dependent features |\n",
    "| **TFT** | TFTModel | Interpretable attention, covariates support | Feature importance, new beach prediction |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583182c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_darts_series(df, target_col='y', id_col='unique_id', time_col='ds', cov_cols=None):\n",
    "    \"\"\"Convert a long-format DataFrame into lists of Darts TimeSeries (target + covariates).\"\"\"\n",
    "    target_series = []\n",
    "    covariate_series = []\n",
    "    \n",
    "    for uid, group in df.groupby(id_col):\n",
    "        group = group.sort_values(time_col).reset_index(drop=True)\n",
    "        if len(group) < INPUT_CHUNK_LENGTH + OUTPUT_CHUNK_LENGTH:\n",
    "            continue\n",
    "        \n",
    "        ts = TimeSeries.from_dataframe(\n",
    "            group, time_col=time_col, value_cols=target_col, freq='h'\n",
    "        )\n",
    "        target_series.append(ts)\n",
    "        \n",
    "        if cov_cols:\n",
    "            available = [c for c in cov_cols if c in group.columns]\n",
    "            cov_ts = TimeSeries.from_dataframe(\n",
    "                group, time_col=time_col, value_cols=available, freq='h'\n",
    "            )\n",
    "            covariate_series.append(cov_ts)\n",
    "    \n",
    "    return target_series, covariate_series if cov_cols else None\n",
    "\n",
    "print(f\"Darts conversion function ready. Features: {len(ALL_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_DARTS and HAS_DARTS:\n",
    "    for ds_name in ['Full24h', 'Night0', 'NightQ1', 'NightMin']:\n",
    "        nf_train = prepared_data[ds_name]['train']\n",
    "        nf_test = prepared_data[ds_name]['test']\n",
    "        \n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"DARTS - {ds_name}\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "        \n",
    "        # Convert to Darts TimeSeries\n",
    "        nf_all = pd.concat([nf_train, nf_test]).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "        \n",
    "        train_series, train_covs = df_to_darts_series(nf_train, cov_cols=ALL_FEATURES)\n",
    "        \n",
    "        # Build full series (train+test) for prediction\n",
    "        full_series, full_covs = df_to_darts_series(nf_all, cov_cols=ALL_FEATURES)\n",
    "        \n",
    "        # Scale\n",
    "        scaler_target = Scaler()\n",
    "        scaler_cov = Scaler()\n",
    "        train_series_scaled = scaler_target.fit_transform(train_series)\n",
    "        train_covs_scaled = scaler_cov.fit_transform(train_covs) if train_covs else None\n",
    "        full_series_scaled = scaler_target.transform(full_series)\n",
    "        full_covs_scaled = scaler_cov.transform(full_covs) if full_covs else None\n",
    "        \n",
    "        # Determine test horizon per series\n",
    "        test_horizon = nf_test.groupby('unique_id').size().min()\n",
    "        horizon = min(OUTPUT_CHUNK_LENGTH, test_horizon)\n",
    "        \n",
    "        print(f\"  Series: {len(train_series)}, Horizon: {horizon}\")\n",
    "        \n",
    "        # === LSTM (BlockRNNModel) ===\n",
    "        print(f\"\\n  LSTM (BlockRNNModel)...\")\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            lstm_model = BlockRNNModel(\n",
    "                model='LSTM',\n",
    "                input_chunk_length=INPUT_CHUNK_LENGTH,\n",
    "                output_chunk_length=horizon,\n",
    "                hidden_dim=64,\n",
    "                n_rnn_layers=2,\n",
    "                dropout=0.1,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                n_epochs=N_EPOCHS,\n",
    "                optimizer_kwargs={'lr': 1e-3},\n",
    "                random_state=42,\n",
    "                pl_trainer_kwargs=PL_TRAINER_KWARGS,\n",
    "            )\n",
    "            \n",
    "            lstm_model.fit(\n",
    "                series=train_series_scaled,\n",
    "                past_covariates=train_covs_scaled,\n",
    "                verbose=False,\n",
    "            )\n",
    "            \n",
    "            # Predict on each series\n",
    "            preds_scaled = lstm_model.predict(\n",
    "                n=horizon,\n",
    "                series=full_series_scaled,\n",
    "                past_covariates=full_covs_scaled,\n",
    "            )\n",
    "            preds = scaler_target.inverse_transform(preds_scaled)\n",
    "            elapsed = time.time() - t0\n",
    "            \n",
    "            # Collect predictions vs actuals\n",
    "            y_true_all, y_pred_all, uids_all = [], [], []\n",
    "            series_ids = sorted(nf_all['unique_id'].unique())\n",
    "            \n",
    "            for i, uid in enumerate(series_ids):\n",
    "                if i >= len(preds):\n",
    "                    break\n",
    "                pred_vals = np.clip(preds[i].values().flatten(), 0, None)\n",
    "                test_sub = nf_test[nf_test['unique_id'] == uid].sort_values('ds').tail(len(pred_vals))\n",
    "                actual = test_sub['y'].values[:len(pred_vals)]\n",
    "                n_match = min(len(actual), len(pred_vals))\n",
    "                y_true_all.extend(actual[:n_match])\n",
    "                y_pred_all.extend(pred_vals[:n_match])\n",
    "                uids_all.extend([uid] * n_match)\n",
    "            \n",
    "            y_true_arr = np.array(y_true_all)\n",
    "            y_pred_arr = np.array(y_pred_all)\n",
    "            \n",
    "            if len(y_true_arr) > 0:\n",
    "                m = calc_metrics(y_true_arr, y_pred_arr, y_true_arr.max())\n",
    "                eval_df = pd.DataFrame({'unique_id': uids_all, 'y': y_true_arr, 'beach': uids_all})\n",
    "                beach_df = eval_per_beach(eval_df, y_pred_arr, 'beach')\n",
    "                avg_rel = beach_df['RelMAE'].mean() if len(beach_df) > 0 else np.nan\n",
    "                \n",
    "                all_results.append({\n",
    "                    'Model': 'LSTM', 'Dataset': ds_name, 'Type': 'Darts',\n",
    "                    'MAE': m['MAE'], 'RMSE': m['RMSE'], 'R2': m['R2'],\n",
    "                    'AvgRelMAE': avg_rel, 'Time': elapsed\n",
    "                })\n",
    "                print(f\"    {elapsed:.1f}s | MAE={m['MAE']:.1f} | RelMAE={avg_rel:.1f}% | R2={m['R2']:.3f}\")\n",
    "            else:\n",
    "                print(\"    No valid predictions\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR: {e}\")\n",
    "            import traceback; traceback.print_exc()\n",
    "        \n",
    "        # === TFT ===\n",
    "        print(f\"\\n  TFT (TFTModel)...\")\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            tft_model = TFTModel(\n",
    "                input_chunk_length=INPUT_CHUNK_LENGTH,\n",
    "                output_chunk_length=horizon,\n",
    "                hidden_size=64,\n",
    "                lstm_layers=2,\n",
    "                num_attention_heads=4,\n",
    "                dropout=0.1,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                n_epochs=N_EPOCHS,\n",
    "                likelihood=QuantileRegression(quantiles=[0.1, 0.25, 0.5, 0.75, 0.9]),\n",
    "                optimizer_kwargs={'lr': 1e-3},\n",
    "                random_state=42,\n",
    "                pl_trainer_kwargs=PL_TRAINER_KWARGS,\n",
    "            )\n",
    "            \n",
    "            tft_model.fit(\n",
    "                series=train_series_scaled,\n",
    "                past_covariates=train_covs_scaled,\n",
    "                verbose=False,\n",
    "            )\n",
    "            \n",
    "            preds_scaled = tft_model.predict(\n",
    "                n=horizon,\n",
    "                series=full_series_scaled,\n",
    "                past_covariates=full_covs_scaled,\n",
    "                num_samples=50,\n",
    "            )\n",
    "            preds = scaler_target.inverse_transform(preds_scaled)\n",
    "            elapsed = time.time() - t0\n",
    "            \n",
    "            y_true_all, y_pred_all, uids_all = [], [], []\n",
    "            \n",
    "            for i, uid in enumerate(series_ids):\n",
    "                if i >= len(preds):\n",
    "                    break\n",
    "                pred_vals = np.clip(preds[i].values().mean(axis=2).flatten(), 0, None)\n",
    "                test_sub = nf_test[nf_test['unique_id'] == uid].sort_values('ds').tail(len(pred_vals))\n",
    "                actual = test_sub['y'].values[:len(pred_vals)]\n",
    "                n_match = min(len(actual), len(pred_vals))\n",
    "                y_true_all.extend(actual[:n_match])\n",
    "                y_pred_all.extend(pred_vals[:n_match])\n",
    "                uids_all.extend([uid] * n_match)\n",
    "            \n",
    "            y_true_arr = np.array(y_true_all)\n",
    "            y_pred_arr = np.array(y_pred_all)\n",
    "            \n",
    "            if len(y_true_arr) > 0:\n",
    "                m = calc_metrics(y_true_arr, y_pred_arr, y_true_arr.max())\n",
    "                eval_df = pd.DataFrame({'unique_id': uids_all, 'y': y_true_arr, 'beach': uids_all})\n",
    "                beach_df = eval_per_beach(eval_df, y_pred_arr, 'beach')\n",
    "                avg_rel = beach_df['RelMAE'].mean() if len(beach_df) > 0 else np.nan\n",
    "                \n",
    "                all_results.append({\n",
    "                    'Model': 'TFT', 'Dataset': ds_name, 'Type': 'Darts',\n",
    "                    'MAE': m['MAE'], 'RMSE': m['RMSE'], 'R2': m['R2'],\n",
    "                    'AvgRelMAE': avg_rel, 'Time': elapsed\n",
    "                })\n",
    "                print(f\"    {elapsed:.1f}s | MAE={m['MAE']:.1f} | RelMAE={avg_rel:.1f}% | R2={m['R2']:.3f}\")\n",
    "            else:\n",
    "                print(\"    No valid predictions\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR: {e}\")\n",
    "            import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "## TFT Interpretability\n",
    "\n",
    "One of TFT's key advantages is built-in interpretability via variable selection networks and attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6g7h8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_DARTS and HAS_DARTS:\n",
    "    try:\n",
    "        from darts.explainability import TFTExplainer\n",
    "        \n",
    "        # Use the last trained TFT model\n",
    "        explainer = TFTExplainer(\n",
    "            tft_model,\n",
    "            background_series=train_series_scaled[0],\n",
    "            background_past_covariates=train_covs_scaled[0] if train_covs_scaled else None,\n",
    "        )\n",
    "        result = explainer.explain()\n",
    "        \n",
    "        # Encoder importance\n",
    "        if hasattr(explainer, '_encoder_importance') and explainer._encoder_importance is not None:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            imp = explainer._encoder_importance.melt().sort_values(by='value').tail(15)\n",
    "            plt.barh(data=imp, y='variable', width='value')\n",
    "            plt.xlabel('Importance')\n",
    "            plt.title('TFT Encoder Variable Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Attention\n",
    "        explainer.plot_attention(result, plot_type='all')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"TFT interpretability plots generated\")\n",
    "    except Exception as e:\n",
    "        print(f\"TFT interpretability not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b206f0",
   "metadata": {},
   "source": [
    "## Optuna Hyperparameter Optimization\n",
    "\n",
    "Optimize on Night0 dataset:\n",
    "- **XGBoost**: n_estimators, max_depth, learning_rate, subsample, colsample_bytree\n",
    "- **LightGBM**: n_estimators, num_leaves, learning_rate, feature_fraction, bagging_fraction\n",
    "- **CatBoost**: iterations, depth, learning_rate, l2_leaf_reg\n",
    "- **LSTM (Darts)**: hidden_dim, n_rnn_layers, learning_rate, dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43817587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_rel_mae(y_true, y_pred, groups):\n",
    "    rel_maes = []\n",
    "    for g in np.unique(groups):\n",
    "        mask = groups == g\n",
    "        if mask.sum() < 3:\n",
    "            continue\n",
    "        yt = y_true[mask]\n",
    "        yp = y_pred[mask]\n",
    "        max_count = yt.max()\n",
    "        if max_count > 0:\n",
    "            rel_maes.append(mean_absolute_error(yt, yp) / max_count * 100)\n",
    "    return np.mean(rel_maes) if rel_maes else 999.0\n",
    "\n",
    "def create_xgb_objective(X_train, y_train, X_val, y_val, groups_val):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'random_state': 42, 'n_jobs': -1, 'verbosity': 0,\n",
    "        }\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = np.clip(model.predict(X_val), 0, None)\n",
    "        return calc_avg_rel_mae(y_val.values, y_pred, groups_val.values)\n",
    "    return objective\n",
    "\n",
    "def create_lgbm_objective(X_train, y_train, X_val, y_val, groups_val):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            'random_state': 42, 'n_jobs': -1, 'verbose': -1,\n",
    "        }\n",
    "        model = LGBMRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = np.clip(model.predict(X_val), 0, None)\n",
    "        return calc_avg_rel_mae(y_val.values, y_pred, groups_val.values)\n",
    "    return objective\n",
    "\n",
    "def create_catboost_objective(X_train, y_train, X_val, y_val, groups_val):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "            'depth': trial.suggest_int('depth', 4, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "            'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),\n",
    "            'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "            'random_state': 42, 'verbose': 0,\n",
    "        }\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = np.clip(model.predict(X_val), 0, None)\n",
    "        return calc_avg_rel_mae(y_val.values, y_pred, groups_val.values)\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_per_dataset = {}\n",
    "\n",
    "if RUN_OPTUNA:\n",
    "    for ds_name in ['Night0']:\n",
    "        data = prepared_data[ds_name]\n",
    "        feature_cols = [c for c in data['train'].columns if c not in ['unique_id', 'ds', 'y']]\n",
    "        \n",
    "        train_nf = data['train']\n",
    "        split_idx = int(len(train_nf) * 0.82)\n",
    "        X_tr = train_nf[feature_cols].iloc[:split_idx]\n",
    "        y_tr = train_nf['y'].iloc[:split_idx]\n",
    "        X_va = train_nf[feature_cols].iloc[split_idx:]\n",
    "        y_va = train_nf['y'].iloc[split_idx:]\n",
    "        groups_va = train_nf['unique_id'].iloc[split_idx:]\n",
    "        \n",
    "        best_models = {}\n",
    "        \n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"OPTUNA - {ds_name} (trials={OPTUNA_TRIALS})\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "        \n",
    "        if HAS_XGB:\n",
    "            print(\"\\n  XGBoost...\")\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(create_xgb_objective(X_tr, y_tr, X_va, y_va, groups_va),\n",
    "                          n_trials=OPTUNA_TRIALS, timeout=OPTUNA_TIMEOUT, show_progress_bar=True)\n",
    "            best_models['XGBoost_Optuna'] = study.best_params\n",
    "            print(f\"    Best AvgRelMAE: {study.best_value:.2f}%\")\n",
    "        \n",
    "        if HAS_LGBM:\n",
    "            print(\"\\n  LightGBM...\")\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(create_lgbm_objective(X_tr, y_tr, X_va, y_va, groups_va),\n",
    "                          n_trials=OPTUNA_TRIALS, timeout=OPTUNA_TIMEOUT, show_progress_bar=True)\n",
    "            best_models['LightGBM_Optuna'] = study.best_params\n",
    "            print(f\"    Best AvgRelMAE: {study.best_value:.2f}%\")\n",
    "        \n",
    "        if HAS_CATBOOST:\n",
    "            print(\"\\n  CatBoost...\")\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(create_catboost_objective(X_tr, y_tr, X_va, y_va, groups_va),\n",
    "                          n_trials=OPTUNA_TRIALS, timeout=OPTUNA_TIMEOUT, show_progress_bar=True)\n",
    "            best_models['CatBoost_Optuna'] = study.best_params\n",
    "            print(f\"    Best AvgRelMAE: {study.best_value:.2f}%\")\n",
    "        \n",
    "        best_models_per_dataset[ds_name] = best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e3c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_OPTUNA and best_models_per_dataset:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EVALUATING OPTUNA MODELS ACROSS ALL DATASETS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for ds_name in datasets.keys():\n",
    "        data = prepared_data[ds_name]\n",
    "        feature_cols = [c for c in data['train'].columns if c not in ['unique_id', 'ds', 'y']]\n",
    "        \n",
    "        X_train_full = data['train'][feature_cols]\n",
    "        y_train_full = data['train']['y']\n",
    "        X_test = data['test'][feature_cols]\n",
    "        y_test = data['test']['y']\n",
    "        \n",
    "        best_models = best_models_per_dataset.get('Night0', {})\n",
    "        \n",
    "        print(f\"\\n  --- {ds_name} ---\")\n",
    "        \n",
    "        for name, params in best_models.items():\n",
    "            t0 = time.time()\n",
    "            \n",
    "            if 'XGBoost' in name:\n",
    "                model = XGBRegressor(**params, random_state=42, n_jobs=-1, verbosity=0)\n",
    "            elif 'LightGBM' in name:\n",
    "                model = LGBMRegressor(**params, random_state=42, n_jobs=-1, verbose=-1)\n",
    "            elif 'CatBoost' in name:\n",
    "                model = CatBoostRegressor(**params, random_state=42, verbose=0)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            model.fit(X_train_full, y_train_full)\n",
    "            y_pred = np.clip(model.predict(X_test), 0, None)\n",
    "            elapsed = time.time() - t0\n",
    "            \n",
    "            m = calc_metrics(y_test.values, y_pred, y_test.max())\n",
    "            \n",
    "            eval_df = data['test'][['unique_id', 'y']].copy()\n",
    "            eval_df['count'] = eval_df['y']\n",
    "            eval_df['beach'] = eval_df['unique_id']\n",
    "            beach_df = eval_per_beach(eval_df, y_pred, 'beach')\n",
    "            avg_rel = beach_df['RelMAE'].mean()\n",
    "            \n",
    "            all_results.append({\n",
    "                'Model': name, 'Dataset': ds_name, 'Type': 'Optuna',\n",
    "                'MAE': m['MAE'], 'RMSE': m['RMSE'], 'R2': m['R2'],\n",
    "                'AvgRelMAE': avg_rel, 'Time': elapsed\n",
    "            })\n",
    "            print(f\"    {name:20s} | {elapsed:5.1f}s | MAE={m['MAE']:.1f} | RelMAE={avg_rel:.1f}% | R2={m['R2']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d572742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_darts_objective(train_series, train_covs, val_series, val_covs, scaler_t, horizon):\n",
    "    def objective(trial):\n",
    "        hidden_dim = trial.suggest_int('hidden_dim', 32, 256)\n",
    "        n_rnn_layers = trial.suggest_int('n_rnn_layers', 1, 3)\n",
    "        lr = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "        dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "        \n",
    "        model = BlockRNNModel(\n",
    "            model='LSTM',\n",
    "            input_chunk_length=INPUT_CHUNK_LENGTH,\n",
    "            output_chunk_length=horizon,\n",
    "            hidden_dim=hidden_dim,\n",
    "            n_rnn_layers=n_rnn_layers,\n",
    "            dropout=dropout,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            n_epochs=20,\n",
    "            optimizer_kwargs={'lr': lr},\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=PL_TRAINER_KWARGS,\n",
    "        )\n",
    "        \n",
    "        model.fit(series=train_series, past_covariates=train_covs, verbose=False)\n",
    "        \n",
    "        preds_scaled = model.predict(n=horizon, series=train_series, past_covariates=train_covs)\n",
    "        preds = scaler_t.inverse_transform(preds_scaled)\n",
    "        \n",
    "        # Simple MAE across all series\n",
    "        total_mae = 0\n",
    "        count = 0\n",
    "        for i in range(min(len(preds), len(val_series))):\n",
    "            pred_vals = np.clip(preds[i].values().flatten(), 0, None)\n",
    "            actual_vals = val_series[i].values().flatten()[:len(pred_vals)]\n",
    "            n = min(len(pred_vals), len(actual_vals))\n",
    "            if n > 0:\n",
    "                total_mae += mean_absolute_error(actual_vals[:n], pred_vals[:n])\n",
    "                count += 1\n",
    "        \n",
    "        return total_mae / max(count, 1)\n",
    "    return objective\n",
    "\n",
    "if RUN_OPTUNA and HAS_DARTS:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"OPTUNA LSTM (Darts) OPTIMIZATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    ds_name = 'Night0'\n",
    "    nf_tr = prepared_data[ds_name]['train']\n",
    "    \n",
    "    # Split train into sub-train and sub-val\n",
    "    split_idx = int(len(nf_tr) * 0.82)\n",
    "    nf_tr_sub = nf_tr.iloc[:split_idx]\n",
    "    nf_va_sub = nf_tr.iloc[split_idx:]\n",
    "    \n",
    "    tr_series, tr_covs = df_to_darts_series(nf_tr_sub, cov_cols=ALL_FEATURES)\n",
    "    va_series, va_covs = df_to_darts_series(nf_va_sub, cov_cols=ALL_FEATURES)\n",
    "    \n",
    "    scaler_t_opt = Scaler()\n",
    "    scaler_c_opt = Scaler()\n",
    "    tr_series_s = scaler_t_opt.fit_transform(tr_series)\n",
    "    tr_covs_s = scaler_c_opt.fit_transform(tr_covs) if tr_covs else None\n",
    "    \n",
    "    horizon_opt = min(OUTPUT_CHUNK_LENGTH, 12)\n",
    "    \n",
    "    print(f\"  Optimizing LSTM (horizon={horizon_opt})...\")\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    try:\n",
    "        study.optimize(\n",
    "            create_lstm_darts_objective(tr_series_s, tr_covs_s, va_series, va_covs, scaler_t_opt, horizon_opt),\n",
    "            n_trials=min(10, OPTUNA_TRIALS),\n",
    "            timeout=OPTUNA_TIMEOUT,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        print(f\"    Best MAE: {study.best_value:.2f}\")\n",
    "        print(f\"    Best params: {study.best_params}\")\n",
    "        best_models_per_dataset.setdefault('Night0', {})['LSTM_Optuna'] = study.best_params\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_params = best_models_per_dataset.get('Night0', {}).get('LSTM_Optuna')\n",
    "\n",
    "if RUN_OPTUNA and HAS_DARTS and lstm_params:\n",
    "    for ds_name in ['Full24h', 'Night0', 'NightQ1', 'NightMin']:\n",
    "        nf_train = prepared_data[ds_name]['train']\n",
    "        nf_test = prepared_data[ds_name]['test']\n",
    "        nf_all = pd.concat([nf_train, nf_test]).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "        \n",
    "        train_s, train_c = df_to_darts_series(nf_train, cov_cols=ALL_FEATURES)\n",
    "        full_s, full_c = df_to_darts_series(nf_all, cov_cols=ALL_FEATURES)\n",
    "        \n",
    "        scaler_t2 = Scaler()\n",
    "        scaler_c2 = Scaler()\n",
    "        train_s_sc = scaler_t2.fit_transform(train_s)\n",
    "        train_c_sc = scaler_c2.fit_transform(train_c) if train_c else None\n",
    "        full_s_sc = scaler_t2.transform(full_s)\n",
    "        full_c_sc = scaler_c2.transform(full_c) if full_c else None\n",
    "        \n",
    "        horizon = min(OUTPUT_CHUNK_LENGTH, nf_test.groupby('unique_id').size().min())\n",
    "        \n",
    "        print(f\"\\n  Evaluating LSTM_Optuna on {ds_name} (horizon={horizon})...\")\n",
    "        \n",
    "        t0 = time.time()\n",
    "        model = BlockRNNModel(\n",
    "            model='LSTM',\n",
    "            input_chunk_length=INPUT_CHUNK_LENGTH,\n",
    "            output_chunk_length=horizon,\n",
    "            hidden_dim=lstm_params.get('hidden_dim', 64),\n",
    "            n_rnn_layers=lstm_params.get('n_rnn_layers', 2),\n",
    "            dropout=lstm_params.get('dropout', 0.1),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            n_epochs=N_EPOCHS,\n",
    "            optimizer_kwargs={'lr': lstm_params.get('learning_rate', 1e-3)},\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=PL_TRAINER_KWARGS,\n",
    "        )\n",
    "        \n",
    "        model.fit(series=train_s_sc, past_covariates=train_c_sc, verbose=False)\n",
    "        preds_scaled = model.predict(n=horizon, series=full_s_sc, past_covariates=full_c_sc)\n",
    "        preds = scaler_t2.inverse_transform(preds_scaled)\n",
    "        elapsed = time.time() - t0\n",
    "        \n",
    "        series_ids = sorted(nf_all['unique_id'].unique())\n",
    "        y_true_all, y_pred_all, uids_all = [], [], []\n",
    "        \n",
    "        for i, uid in enumerate(series_ids):\n",
    "            if i >= len(preds): break\n",
    "            pred_vals = np.clip(preds[i].values().flatten(), 0, None)\n",
    "            test_sub = nf_test[nf_test['unique_id'] == uid].sort_values('ds').tail(len(pred_vals))\n",
    "            actual = test_sub['y'].values[:len(pred_vals)]\n",
    "            n_match = min(len(actual), len(pred_vals))\n",
    "            y_true_all.extend(actual[:n_match])\n",
    "            y_pred_all.extend(pred_vals[:n_match])\n",
    "            uids_all.extend([uid] * n_match)\n",
    "        \n",
    "        y_true_arr = np.array(y_true_all)\n",
    "        y_pred_arr = np.array(y_pred_all)\n",
    "        \n",
    "        if len(y_true_arr) > 0:\n",
    "            m = calc_metrics(y_true_arr, y_pred_arr, y_true_arr.max())\n",
    "            eval_df = pd.DataFrame({'unique_id': uids_all, 'y': y_true_arr, 'beach': uids_all})\n",
    "            beach_df = eval_per_beach(eval_df, y_pred_arr, 'beach')\n",
    "            avg_rel = beach_df['RelMAE'].mean()\n",
    "            \n",
    "            all_results.append({\n",
    "                'Model': 'LSTM_Optuna', 'Dataset': ds_name, 'Type': 'Optuna+Darts',\n",
    "                'MAE': m['MAE'], 'RMSE': m['RMSE'], 'R2': m['R2'],\n",
    "                'AvgRelMAE': avg_rel, 'Time': elapsed\n",
    "            })\n",
    "            print(f\"    {elapsed:.1f}s | MAE={m['MAE']:.1f} | RelMAE={avg_rel:.1f}% | R2={m['R2']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce557d2b",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b498851",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_results)\n",
    "beach_results_df = pd.concat(all_beach_results, ignore_index=True) if all_beach_results else pd.DataFrame()\n",
    "\n",
    "save_dir = Path(SAVE_DIR)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_df.to_csv(save_dir / 'results.csv', index=False)\n",
    "if len(beach_results_df) > 0:\n",
    "    beach_results_df.to_csv(save_dir / 'beach_results.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESULTS BY DATASET\")\n",
    "print(\"=\" * 70)\n",
    "for ds in datasets.keys():\n",
    "    sub = results_df[results_df['Dataset'] == ds].sort_values('AvgRelMAE')\n",
    "    if len(sub) == 0:\n",
    "        continue\n",
    "    print(f\"\\n{ds}:\")\n",
    "    print(sub[['Model', 'Type', 'MAE', 'R2', 'AvgRelMAE', 'Time']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = results_df.pivot_table(index='Model', columns='Dataset', values='AvgRelMAE')\n",
    "print(\"\\nRelMAE (%) by Model x Dataset:\")\n",
    "print(pivot.round(1).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb5ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results_df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    pivot = results_df.pivot_table(index='Model', columns='Dataset', values='AvgRelMAE')\n",
    "    pivot = pivot.loc[pivot.mean(axis=1).sort_values().index]\n",
    "    pivot.plot(kind='bar', ax=axes[0], width=0.8)\n",
    "    axes[0].set_ylabel('Avg RelMAE (%)')\n",
    "    axes[0].set_title('Model Performance (lower is better)')\n",
    "    axes[0].legend(title='Dataset')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    pivot_r2 = results_df.pivot_table(index='Model', columns='Dataset', values='R2')\n",
    "    pivot_r2 = pivot_r2.loc[pivot_r2.mean(axis=1).sort_values(ascending=False).index]\n",
    "    pivot_r2.plot(kind='bar', ax=axes[1], width=0.8)\n",
    "    axes[1].set_ylabel('R²')\n",
    "    axes[1].set_title('R² Score (higher is better)')\n",
    "    axes[1].legend(title='Dataset')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'comparison.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BEST MODEL PER DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for ds in datasets.keys():\n",
    "    sub = results_df[results_df['Dataset'] == ds].dropna(subset=['AvgRelMAE'])\n",
    "    if len(sub) == 0:\n",
    "        continue\n",
    "    best = sub.loc[sub['AvgRelMAE'].idxmin()]\n",
    "    print(f\"\\n{ds}: Best = {best['Model']} ({best['Type']})\")\n",
    "    print(f\"  MAE: {best['MAE']:.2f}\")\n",
    "    print(f\"  RelMAE: {best['AvgRelMAE']:.1f}%\")\n",
    "    print(f\"  R²: {best['R2']:.3f}\")\n",
    "    print(f\"  Time: {best['Time']:.1f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
