{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7acafb40",
   "metadata": {},
   "source": [
    "# Beach Crowd Prediction — LSTM, TFT, TiDE + Optuna Optimization\n",
    "\n",
    "This notebook compares models across **three dataset strategies**:\n",
    "1. **Daytime only** — remove night hours (6PM–6AM)\n",
    "2. **Full 24h** — keep all data including noisy night counts\n",
    "3. **Night = 0** — keep 24h but replace night counts with 0\n",
    "\n",
    "Models tested:\n",
    "- **Sklearn baselines**: Lasso, RandomForest, XGBoost, LightGBM, CatBoost\n",
    "- **NeuralForecast**: LSTM, TFT, TiDE\n",
    "- **Optuna-optimized**: XGBoost, LightGBM, CatBoost, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5d0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATHS ===\n",
    "CACHE_DIR = \"cache/predictions\"\n",
    "COUNTING_MODEL = \"bayesian_vgg19\"\n",
    "SAVE_DIR = \"models/tft_chunks\"\n",
    "\n",
    "# === SAMPLING ===\n",
    "SAMPLE_FRAC = 1.0\n",
    "MAX_BEACHES = None\n",
    "\n",
    "# === TFT PARAMETERS ===\n",
    "MAX_STEPS = 500\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "INPUT_SIZE = 48\n",
    "HORIZON = 168  # 1 week = 7 days\n",
    "\n",
    "# === TIME ===\n",
    "NIGHT_START = 20\n",
    "NIGHT_END = 6\n",
    "\n",
    "# === FLAGS ===\n",
    "RUN_SKLEARN = False\n",
    "RUN_NEURALFORECAST = True\n",
    "RUN_OPTUNA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec0f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "for pkg in [\"neuralforecast\", \"utilsforecast\"]:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfaae9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps | PyTorch: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "import torch\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import TFT\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "\n",
    "HAS_NF = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    ACCELERATOR = 'gpu'\n",
    "    DEVICES = 1\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    ACCELERATOR = 'mps'\n",
    "    DEVICES = 1\n",
    "else:\n",
    "    ACCELERATOR = 'cpu'\n",
    "    DEVICES = 1\n",
    "\n",
    "print(f\"Device: {ACCELERATOR} | PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13539953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred, max_count):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rel_mae = (mae / max_count) * 100 if max_count > 0 else 0\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'RelMAE': rel_mae}\n",
    "\n",
    "def eval_per_beach(df, y_pred, beach_col='unique_id'):\n",
    "    results = []\n",
    "    for b in df[beach_col].unique():\n",
    "        mask = df[beach_col] == b\n",
    "        if mask.sum() < 3:\n",
    "            continue\n",
    "        y_true = df.loc[mask, 'y'].values if 'y' in df.columns else df.loc[mask, 'count'].values\n",
    "        y_p = y_pred[mask.values] if hasattr(mask, 'values') else y_pred[mask]\n",
    "        max_count = y_true.max()\n",
    "        m = calc_metrics(y_true, y_p, max_count)\n",
    "        m['camera'] = b\n",
    "        m['max_count'] = max_count\n",
    "        m['n'] = mask.sum()\n",
    "        results.append(m)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980944f",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache(cache_dir, model):\n",
    "    cache_path = Path(cache_dir) / model\n",
    "    records = []\n",
    "    for jf in cache_path.rglob(\"*.json\"):\n",
    "        try:\n",
    "            with open(jf) as f:\n",
    "                r = json.load(f)\n",
    "            if 'error' not in r:\n",
    "                records.append(r)\n",
    "        except: pass\n",
    "    \n",
    "    rows = []\n",
    "    for r in records:\n",
    "        row = {\n",
    "            'beach': r.get('beach') or r.get('beach_folder'),\n",
    "            'beach_folder': r.get('beach_folder'),\n",
    "            'datetime': r.get('datetime'),\n",
    "            'count': r.get('count')\n",
    "        }\n",
    "        for k, v in r.get('weather', {}).items():\n",
    "            row[k] = v\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_raw = load_cache(CACHE_DIR, COUNTING_MODEL)\n",
    "print(f\"Loaded: {len(df_raw)} rows, {df_raw['beach'].nunique()} beaches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26af23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDE = ['livecampro/001', 'livecampro/011', 'livecampro/018', 'livecampro/021',\n",
    "    'livecampro/030', 'livecampro/039', 'livecampro/070', 'MultimediaTres/PortAndratx',\n",
    "    'SeeTheWorld/mallorca_pancam', 'skyline/es-pujols']\n",
    "EXCLUDE_PREFIX = ['ibred', 'ClubNauticSoller', 'Guenthoer', 'youtube']\n",
    "\n",
    "before = len(df_raw)\n",
    "df_raw = df_raw[~df_raw['beach_folder'].isin(EXCLUDE)]\n",
    "for p in EXCLUDE_PREFIX:\n",
    "    df_raw = df_raw[~df_raw['beach_folder'].str.startswith(p, na=False)]\n",
    "print(f\"Filtered: {before} -> {len(df_raw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53950688",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_FRAC < 1.0:\n",
    "    df_raw = df_raw.sample(frac=SAMPLE_FRAC, random_state=42).sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "if MAX_BEACHES:\n",
    "    top = df_raw['beach'].value_counts().head(MAX_BEACHES).index.tolist()\n",
    "    df_raw = df_raw[df_raw['beach'].isin(top)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Final: {len(df_raw)} rows, {df_raw['beach'].nunique()} beaches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)\n",
    "df['is_night'] = ((df['hour'] >= NIGHT_START) | (df['hour'] <= NIGHT_END)).astype(int)\n",
    "\n",
    "WEATHER_COLS = [c for c in df.columns if c.startswith('ae_') or c.startswith('om_')]\n",
    "TEMPORAL_COLS = ['hour', 'day_of_week', 'month', 'is_weekend', 'is_summer', 'is_night']\n",
    "ALL_FEATURES = WEATHER_COLS + TEMPORAL_COLS\n",
    "\n",
    "df = df.dropna(subset=ALL_FEATURES + ['count']).reset_index(drop=True)\n",
    "good = df.groupby('beach')['count'].max()\n",
    "good = good[good > 20].index.tolist()\n",
    "df = df[df['beach'].isin(good)].reset_index(drop=True)\n",
    "\n",
    "print(f\"After cleaning: {len(df)} rows, {len(good)} beaches\")\n",
    "print(f\"Features: {len(ALL_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff774dc",
   "metadata": {},
   "source": [
    "## Create Three Dataset Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ff4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_daytime = df[df['is_night'] == 0].copy().reset_index(drop=True)\n",
    "ds_full24h = df.copy()\n",
    "ds_night0 = df.copy()\n",
    "ds_night0.loc[ds_night0['is_night'] == 1, 'count'] = 0.0\n",
    "\n",
    "ds_nightq1 = df.copy()\n",
    "q1_per_beach = ds_nightq1[ds_nightq1['is_night'] == 0].groupby('beach')['count'].quantile(0.25)\n",
    "ds_nightq1.loc[ds_nightq1['is_night'] == 1, 'count'] = ds_nightq1.loc[ds_nightq1['is_night'] == 1, 'beach'].map(q1_per_beach).fillna(0)\n",
    "\n",
    "ds_nightmin = df.copy()\n",
    "min_per_beach = ds_nightmin[ds_nightmin['is_night'] == 0].groupby('beach')['count'].min()\n",
    "ds_nightmin.loc[ds_nightmin['is_night'] == 1, 'count'] = ds_nightmin.loc[ds_nightmin['is_night'] == 1, 'beach'].map(min_per_beach).fillna(0)\n",
    "\n",
    "datasets = {'Daytime': ds_daytime, 'Full24h': ds_full24h, 'Night0': ds_night0, 'NightQ1': ds_nightq1, 'NightMin': ds_nightmin}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, d in datasets.items():\n",
    "    night_rows = d[d['is_night'] == 1] if 'is_night' in d.columns else pd.DataFrame()\n",
    "    day_rows = d[d['is_night'] == 0] if 'is_night' in d.columns else d\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Total rows:     {len(d)}\")\n",
    "    print(f\"  Beaches:        {d['beach'].nunique()}\")\n",
    "    print(f\"  Night rows:     {len(night_rows)} ({len(night_rows)/len(d)*100:.1f}%)\")\n",
    "    print(f\"  Day rows:       {len(day_rows)} ({len(day_rows)/len(d)*100:.1f}%)\")\n",
    "    print(f\"  Count mean:     {d['count'].mean():.1f}\")\n",
    "    print(f\"  Count max:      {d['count'].max():.1f}\")\n",
    "    print(f\"  Zeros:          {(d['count'] == 0).sum()} ({(d['count'] == 0).sum()/len(d)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccdb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsforecast.preprocessing import fill_gaps\n",
    "\n",
    "def to_nf_format(df, id_col='beach_folder'):\n",
    "    cols = ['datetime', id_col, 'count'] + ALL_FEATURES\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    nf_df = df[cols].copy()\n",
    "    nf_df = nf_df.rename(columns={'datetime': 'ds', id_col: 'unique_id', 'count': 'y'})\n",
    "    return nf_df\n",
    "\n",
    "def prepare_nf_data(df, freq='h'):\n",
    "    nf = to_nf_format(df)\n",
    "    nf = nf.groupby(['unique_id', 'ds']).mean(numeric_only=True).reset_index()\n",
    "    nf = fill_gaps(nf, freq=freq)\n",
    "    for col in nf.select_dtypes(include=[np.number]).columns:\n",
    "        nf[col] = nf.groupby('unique_id')[col].transform(\n",
    "            lambda x: x.interpolate(method='linear').ffill().bfill()\n",
    "        )\n",
    "    return nf\n",
    "\n",
    "def create_temporal_chunks(df, n_chunks=6):\n",
    "    date_min = df['datetime'].min()\n",
    "    date_max = df['datetime'].max()\n",
    "    total_days = (date_max - date_min).days\n",
    "    chunk_days = total_days // n_chunks\n",
    "\n",
    "    boundaries = []\n",
    "    for i in range(n_chunks + 1):\n",
    "        boundaries.append(date_min + pd.Timedelta(days=i * chunk_days))\n",
    "    boundaries[-1] = date_max + pd.Timedelta(hours=1)\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(n_chunks):\n",
    "        mask = (df['datetime'] >= boundaries[i]) & (df['datetime'] < boundaries[i+1])\n",
    "        chunk = df[mask].copy()\n",
    "        chunks.append({\n",
    "            'data': chunk,\n",
    "            'start': boundaries[i],\n",
    "            'end': boundaries[i+1] - pd.Timedelta(hours=1),\n",
    "            'label': f\"C{i+1}: {boundaries[i].strftime('%b %d')}→{(boundaries[i+1]-pd.Timedelta(hours=1)).strftime('%b %d')}\"\n",
    "        })\n",
    "    return chunks, boundaries\n",
    "\n",
    "N_CHUNKS = 6\n",
    "\n",
    "date_min = df['datetime'].min()\n",
    "date_max = df['datetime'].max()\n",
    "total_days = (date_max - date_min).days\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"TEMPORAL CHUNKING: {total_days} days → {N_CHUNKS} chunks of ~{total_days//N_CHUNKS} days\")\n",
    "print(f\"Date range: {date_min.date()} to {date_max.date()}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_chunks = {}\n",
    "for ds_name in datasets.keys():\n",
    "    chunks, boundaries = create_temporal_chunks(datasets[ds_name], N_CHUNKS)\n",
    "    all_chunks[ds_name] = chunks\n",
    "    print(f\"\\n{ds_name}:\")\n",
    "    for c in chunks:\n",
    "        print(f\"  {c['label']} | {len(c['data'])} rows\")\n",
    "\n",
    "# --- SIMPLE SLIDING: train=2 chunks, val=1, test=1 ---\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SIMPLE SLIDING WINDOW (train=2 chunks, val=1, test=1)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "simple_windows_all = {}\n",
    "for ds_name in datasets.keys():\n",
    "    chunks = all_chunks[ds_name]\n",
    "    windows = []\n",
    "    for i in range(len(chunks) - 3):\n",
    "        train_data = pd.concat([chunks[i]['data'], chunks[i+1]['data']])\n",
    "        windows.append({\n",
    "            'name': f\"SW{i+1}\",\n",
    "            'train_chunks': [chunks[i], chunks[i+1]],\n",
    "            'train_data': train_data,\n",
    "            'val_data': chunks[i+2]['data'],\n",
    "            'test_data': chunks[i+3]['data'],\n",
    "            'train_label': f\"{chunks[i]['label'].split(':')[0]}+{chunks[i+1]['label'].split(':')[0]} (2 chunks)\",\n",
    "            'val_label': chunks[i+2]['label'],\n",
    "            'test_label': chunks[i+3]['label'],\n",
    "        })\n",
    "    simple_windows_all[ds_name] = windows\n",
    "\n",
    "    print(f\"\\n{ds_name}:\")\n",
    "    for w in windows:\n",
    "        print(f\"  {w['name']}: Train={w['train_label']} ({len(w['train_data'])} rows) | \"\n",
    "              f\"Val={w['val_label']} | Test={w['test_label']}\")\n",
    "\n",
    "# --- ROLLING WINDOWS: train=expanding, val=1, test=1 ---\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ROLLING WINDOW EXPERIMENTS (train=expanding, val=1 chunk, test=1 chunk)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "rolling_windows = {}\n",
    "for ds_name in datasets.keys():\n",
    "    chunks = all_chunks[ds_name]\n",
    "    windows = []\n",
    "    for test_idx in range(2, N_CHUNKS):\n",
    "        val_idx = test_idx - 1\n",
    "        train_chunks = chunks[:val_idx]\n",
    "        windows.append({\n",
    "            'name': f\"W{len(windows)+1}\",\n",
    "            'train_chunks': train_chunks,\n",
    "            'train_data': pd.concat([c['data'] for c in train_chunks]),\n",
    "            'val_data': chunks[val_idx]['data'],\n",
    "            'test_data': chunks[test_idx]['data'],\n",
    "            'train_label': f\"{train_chunks[0]['label'].split(':')[0]}→{train_chunks[-1]['label'].split(':')[0]} ({len(train_chunks)} chunks)\",\n",
    "            'val_label': chunks[val_idx]['label'],\n",
    "            'test_label': chunks[test_idx]['label'],\n",
    "        })\n",
    "    rolling_windows[ds_name] = windows\n",
    "\n",
    "    print(f\"\\n{ds_name}:\")\n",
    "    for w in windows:\n",
    "        print(f\"  {w['name']}: Train={w['train_label']} ({len(w['train_data'])} rows) | \"\n",
    "              f\"Val={w['val_label']} | Test={w['test_label']}\")\n",
    "\n",
    "# --- SPLIT-GAP: first 40% + last 40%, skip middle 20% ---\n",
    "# Simulates having 2022 data + 2025 data with years missing in between\n",
    "# Tests: does a model trained on disconnected periods generalize?\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SPLIT-GAP EXPERIMENT (40% early | 20% gap | 40% late)\")\n",
    "print(\"Simulates: 2022 data + 2025 data, no data in between\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "split_gap_windows = {}\n",
    "for ds_name in datasets.keys():\n",
    "    ds = datasets[ds_name].sort_values('datetime').reset_index(drop=True)\n",
    "    n = len(ds)\n",
    "\n",
    "    early = ds.iloc[:int(n * 0.4)]\n",
    "    late = ds.iloc[int(n * 0.6):]\n",
    "    gap_start = ds.iloc[int(n * 0.4)]['datetime']\n",
    "    gap_end = ds.iloc[int(n * 0.6)]['datetime']\n",
    "\n",
    "    def split_period(period_df, period_name):\n",
    "        np_ = len(period_df)\n",
    "        tr = period_df.iloc[:int(np_ * 0.6)]\n",
    "        va = period_df.iloc[int(np_ * 0.6):int(np_ * 0.8)]\n",
    "        te = period_df.iloc[int(np_ * 0.8):]\n",
    "        return {\n",
    "            'name': period_name,\n",
    "            'train_data': tr, 'val_data': va, 'test_data': te,\n",
    "            'train_label': f\"{period_name} train ({tr['datetime'].min().strftime('%b %d')}→{tr['datetime'].max().strftime('%b %d')})\",\n",
    "            'val_label': f\"{period_name} val ({va['datetime'].min().strftime('%b %d')}→{va['datetime'].max().strftime('%b %d')})\",\n",
    "            'test_label': f\"{period_name} test ({te['datetime'].min().strftime('%b %d')}→{te['datetime'].max().strftime('%b %d')})\",\n",
    "        }\n",
    "\n",
    "    early_split = split_period(early, \"Early\")\n",
    "    late_split = split_period(late, \"Late\")\n",
    "\n",
    "    combined_train = pd.concat([early_split['train_data'], late_split['train_data']])\n",
    "    combined = {\n",
    "        'name': \"Combined\",\n",
    "        'train_data': combined_train,\n",
    "        'val_data': late_split['val_data'],\n",
    "        'test_data': late_split['test_data'],\n",
    "        'train_label': f\"Early+Late train ({len(combined_train)} rows, gap={gap_start.strftime('%b %d')}→{gap_end.strftime('%b %d')})\",\n",
    "        'val_label': late_split['val_label'],\n",
    "        'test_label': late_split['test_label'],\n",
    "    }\n",
    "\n",
    "    split_gap_windows[ds_name] = {\n",
    "        'early': early_split,\n",
    "        'late': late_split,\n",
    "        'combined': combined,\n",
    "        'gap_start': gap_start,\n",
    "        'gap_end': gap_end,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{ds_name}:\")\n",
    "    print(f\"  Early: {early['datetime'].min().strftime('%b %d')} → {early['datetime'].max().strftime('%b %d')} ({len(early)} rows)\")\n",
    "    print(f\"  Gap:   {gap_start.strftime('%b %d')} → {gap_end.strftime('%b %d')}\")\n",
    "    print(f\"  Late:  {late['datetime'].min().strftime('%b %d')} → {late['datetime'].max().strftime('%b %d')} ({len(late)} rows)\")\n",
    "    print(f\"  Experiments:\")\n",
    "    for exp in [early_split, late_split, combined]:\n",
    "        print(f\"    {exp['name']:10s} | train={len(exp['train_data']):5d} | val={len(exp['val_data']):5d} | test={len(exp['test_data']):5d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beafbbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. SIMPLE SLIDING WINDOW (2 chunks train) ===\n",
    "chunks = all_chunks['Night0']\n",
    "simple_windows = simple_windows_all['Night0']\n",
    "example_uid = df['beach_folder'].value_counts().idxmax()\n",
    "ds_show = datasets['Night0']\n",
    "example = ds_show[ds_show['beach_folder'] == example_uid].sort_values('datetime')\n",
    "\n",
    "c_train = '#2196F3'\n",
    "c_val = '#FF9800'\n",
    "c_test = '#F44336'\n",
    "\n",
    "fig, axes = plt.subplots(len(simple_windows) + 1, 1,\n",
    "                         figsize=(18, 3 * (len(simple_windows) + 1)), sharex=True)\n",
    "\n",
    "axes[0].plot(example['datetime'], example['count'], linewidth=0.6, color='gray')\n",
    "for c in chunks:\n",
    "    axes[0].axvline(c['start'], color='black', linestyle=':', linewidth=0.8, alpha=0.5)\n",
    "    axes[0].text(c['start'], example['count'].max() * 0.95, c['label'][:15], fontsize=7, va='top')\n",
    "axes[0].set_title(f'Full Series — {example_uid[:40]} | {N_CHUNKS} chunks', fontsize=10, loc='left')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "for w_idx, w in enumerate(simple_windows):\n",
    "    ax = axes[w_idx + 1]\n",
    "    ax.plot(example['datetime'], example['count'], linewidth=0.3, color='lightgray', zorder=1)\n",
    "\n",
    "    for tc in w['train_chunks']:\n",
    "        ax.axvspan(tc['start'], tc['end'], alpha=0.25, color=c_train, zorder=2)\n",
    "\n",
    "    val_chunk = chunks[w_idx + 2]\n",
    "    test_chunk = chunks[w_idx + 3]\n",
    "    ax.axvspan(val_chunk['start'], val_chunk['end'], alpha=0.25, color=c_val, zorder=2)\n",
    "    ax.axvspan(test_chunk['start'], test_chunk['end'], alpha=0.3, color=c_test, zorder=2)\n",
    "\n",
    "    for tc in w['train_chunks']:\n",
    "        ax.axvline(tc['start'], color='black', linestyle='--', linewidth=0.5, zorder=3)\n",
    "    ax.axvline(val_chunk['start'], color='black', linestyle='--', linewidth=0.8, zorder=3)\n",
    "    ax.axvline(test_chunk['start'], color='black', linestyle='--', linewidth=0.8, zorder=3)\n",
    "\n",
    "    t_patch = mpatches.Patch(color=c_train, alpha=0.4, label=f\"Train: {w['train_label']}\")\n",
    "    v_patch = mpatches.Patch(color=c_val, alpha=0.4, label=f\"Val: {w['val_label']}\")\n",
    "    te_patch = mpatches.Patch(color=c_test, alpha=0.4, label=f\"Test: {w['test_label']}\")\n",
    "    ax.legend(handles=[t_patch, v_patch, te_patch], loc='upper right', fontsize=7)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f\"{w['name']}: {w['train_label']} → val → test\", fontsize=10, loc='left')\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.suptitle('Simple Sliding Window — Train=2 Chunks, Val=1, Test=1', fontsize=13, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === 2. EXPANDING ROLLING WINDOW ===\n",
    "rw = rolling_windows['Night0']\n",
    "\n",
    "fig, axes = plt.subplots(len(rw) + 1, 1, figsize=(18, 3 * (len(rw) + 1)), sharex=True)\n",
    "\n",
    "axes[0].plot(example['datetime'], example['count'], linewidth=0.6, color='gray')\n",
    "for c in chunks:\n",
    "    axes[0].axvline(c['start'], color='black', linestyle=':', linewidth=0.8, alpha=0.5)\n",
    "    axes[0].text(c['start'], example['count'].max() * 0.95, c['label'][:15], fontsize=7, va='top')\n",
    "axes[0].set_title(f'Full Series — {example_uid[:40]} | {N_CHUNKS} chunks', fontsize=10, loc='left')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "for w_idx, w in enumerate(rw):\n",
    "    ax = axes[w_idx + 1]\n",
    "    ax.plot(example['datetime'], example['count'], linewidth=0.3, color='lightgray', zorder=1)\n",
    "\n",
    "    for tc in w['train_chunks']:\n",
    "        ax.axvspan(tc['start'], tc['end'], alpha=0.25, color=c_train, zorder=2)\n",
    "\n",
    "    val_chunk = chunks[[i for i, c in enumerate(chunks) if c['label'] == w['val_label']][0]]\n",
    "    test_chunk = chunks[[i for i, c in enumerate(chunks) if c['label'] == w['test_label']][0]]\n",
    "    ax.axvspan(val_chunk['start'], val_chunk['end'], alpha=0.25, color=c_val, zorder=2)\n",
    "    ax.axvspan(test_chunk['start'], test_chunk['end'], alpha=0.3, color=c_test, zorder=2)\n",
    "\n",
    "    for tc in w['train_chunks']:\n",
    "        ax.axvline(tc['start'], color='black', linestyle='--', linewidth=0.5, zorder=3)\n",
    "    ax.axvline(val_chunk['start'], color='black', linestyle='--', linewidth=0.8, zorder=3)\n",
    "    ax.axvline(test_chunk['start'], color='black', linestyle='--', linewidth=0.8, zorder=3)\n",
    "\n",
    "    t_patch = mpatches.Patch(color=c_train, alpha=0.4, label=f\"Train: {w['train_label']}\")\n",
    "    v_patch = mpatches.Patch(color=c_val, alpha=0.4, label=f\"Val: {w['val_label']}\")\n",
    "    te_patch = mpatches.Patch(color=c_test, alpha=0.4, label=f\"Test: {w['test_label']}\")\n",
    "    ax.legend(handles=[t_patch, v_patch, te_patch], loc='upper right', fontsize=7)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f\"{w['name']}: train={len(w['train_chunks'])} chunks (expanding)\", fontsize=10, loc='left')\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.suptitle('Expanding Rolling Window — Growing Train, Val=1, Test=1', fontsize=13, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === 3. SPLIT-GAP VISUALIZATION ===\n",
    "sg = split_gap_windows['Night0']\n",
    "c_gap = '#9E9E9E'\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(18, 12), sharex=True)\n",
    "\n",
    "axes[0].plot(example['datetime'], example['count'], linewidth=0.6, color='gray')\n",
    "axes[0].axvspan(sg['gap_start'], sg['gap_end'], alpha=0.3, color=c_gap, zorder=2)\n",
    "axes[0].text(sg['gap_start'] + (sg['gap_end'] - sg['gap_start'])/2, example['count'].max() * 0.9,\n",
    "            'GAP (20%)', ha='center', fontsize=9, fontweight='bold', color='gray')\n",
    "axes[0].set_title('Full Series — Split-Gap Layout', fontsize=10, loc='left')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "labels = ['Early Only', 'Late Only', 'Combined (Early+Late)']\n",
    "exp_keys = ['early', 'late', 'combined']\n",
    "\n",
    "for ax_idx, (label, key) in enumerate(zip(labels, exp_keys)):\n",
    "    ax = axes[ax_idx + 1]\n",
    "    ax.plot(example['datetime'], example['count'], linewidth=0.3, color='lightgray', zorder=1)\n",
    "    ax.axvspan(sg['gap_start'], sg['gap_end'], alpha=0.15, color=c_gap, zorder=2)\n",
    "\n",
    "    exp = sg[key]\n",
    "    tr, va, te = exp['train_data'], exp['val_data'], exp['test_data']\n",
    "\n",
    "    ax.axvspan(tr['datetime'].min(), tr['datetime'].max(), alpha=0.25, color=c_train, zorder=3)\n",
    "    ax.axvspan(va['datetime'].min(), va['datetime'].max(), alpha=0.25, color=c_val, zorder=3)\n",
    "    ax.axvspan(te['datetime'].min(), te['datetime'].max(), alpha=0.3, color=c_test, zorder=3)\n",
    "\n",
    "    t_patch = mpatches.Patch(color=c_train, alpha=0.4, label=f\"Train ({len(tr)} rows)\")\n",
    "    v_patch = mpatches.Patch(color=c_val, alpha=0.4, label=f\"Val ({len(va)} rows)\")\n",
    "    te_patch = mpatches.Patch(color=c_test, alpha=0.4, label=f\"Test ({len(te)} rows)\")\n",
    "    g_patch = mpatches.Patch(color=c_gap, alpha=0.3, label='Gap (20%)')\n",
    "    ax.legend(handles=[t_patch, v_patch, te_patch, g_patch], loc='upper right', fontsize=7)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'{label}', fontsize=10, loc='left')\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.suptitle('Split-Gap — Simulating 2022 + 2025 Disconnected Periods', fontsize=13, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8846f",
   "metadata": {},
   "source": [
    "## TFT — Sliding Window Experiments\n",
    "\n",
    "For each dataset strategy, train TFT on chunk *i*, validate on chunk *i+1*, test on chunk *i+2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a2402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# SIMPLE SLIDING — Full24h\n",
      "######################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  SW1 | h=168 | val=503 | series=16\n",
      "    Train: C1+C2 (2 chunks) (23832 rows)\n",
      "    Val:   C3: Sep 16→Oct 18 | Test: C4: Oct 18→Nov 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                    | Type                     | Params | Mode \n",
      "-----------------------------------------------------------------------------\n",
      "0 | loss                    | MAE                      | 0      | train\n",
      "1 | padder_train            | ConstantPad1d            | 0      | train\n",
      "2 | scaler                  | TemporalNorm             | 0      | train\n",
      "3 | embedding               | TFTEmbedding             | 4.7 K  | train\n",
      "4 | temporal_encoder        | TemporalCovariateEncoder | 977 K  | train\n",
      "5 | temporal_fusion_decoder | TemporalFusionDecoder    | 64.8 K | train\n",
      "6 | output_adapter          | Linear                   | 65     | train\n",
      "-----------------------------------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.187     Total estimated model params size (MB)\n",
      "368       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377e30380c93481caca8e51bda0b32e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63dc0d064bc4f56854af378ca92864f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842aa7ecafe245beb8cd6be3b8018296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ERROR: name 'exit' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py\", line 48, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py\", line 599, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py\", line 1012, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py\", line 1056, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "    ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
      "    self.advance()\n",
      "    ~~~~~~~~~~~~^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 152, in run\n",
      "    self.advance(data_fetcher)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 344, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 192, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 270, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        trainer,\n",
      "        ^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        train_step_and_backward_closure,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py\", line 176, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/core/module.py\", line 1328, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/core/optimizer.py\", line 154, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 123, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\", line 517, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py\", line 82, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 109, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 146, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 131, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py\", line 328, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
      "    return self.lightning_module.training_step(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/neuralforecast/common/_base_model.py\", line 1774, in training_step\n",
      "    train_loss_log = loss.detach().item()\n",
      "                     ~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/vk/964kj82949qg5x1wr_qg33400000gn/T/ipykernel_51793/1831478590.py\", line 44, in run_tft_experiment\n",
      "    nf.fit(df=nf_train_val, val_size=val_size)\n",
      "    ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/neuralforecast/core.py\", line 570, in fit\n",
      "    self.models[i] = model.fit(\n",
      "                     ~~~~~~~~~^\n",
      "        self.dataset, val_size=val_size, distributed_config=distributed_config\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/neuralforecast/common/_base_model.py\", line 1924, in fit\n",
      "    return self._fit(\n",
      "           ~~~~~~~~~^\n",
      "        dataset=dataset,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        distributed_config=distributed_config,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/neuralforecast/common/_base_model.py\", line 602, in _fit\n",
      "    trainer.fit(model, datamodule=datamodule)\n",
      "    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py\", line 561, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py\", line 65, in _call_and_handle_interrupt\n",
      "    exit(1)\n",
      "    ^^^^\n",
      "NameError: name 'exit' is not defined\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  SW2 | h=168 | val=553 | series=16\n",
      "    Train: C2+C3 (2 chunks) (22461 rows)\n",
      "    Val:   C4: Oct 18→Nov 19 | Test: C5: Nov 19→Dec 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                    | Type                     | Params | Mode \n",
      "-----------------------------------------------------------------------------\n",
      "0 | loss                    | MAE                      | 0      | train\n",
      "1 | padder_train            | ConstantPad1d            | 0      | train\n",
      "2 | scaler                  | TemporalNorm             | 0      | train\n",
      "3 | embedding               | TFTEmbedding             | 4.7 K  | train\n",
      "4 | temporal_encoder        | TemporalCovariateEncoder | 977 K  | train\n",
      "5 | temporal_fusion_decoder | TemporalFusionDecoder    | 64.8 K | train\n",
      "6 | output_adapter          | Linear                   | 65     | train\n",
      "-----------------------------------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.187     Total estimated model params size (MB)\n",
      "368       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf699725b29244b38d997a6b705bfaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976a02322f9347869cb50673f19efd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d02b9a007d04bf999bae1d2a51c2652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d594670bd24cd5871c79ae4a542e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = []\n",
    "all_cv_details = []\n",
    "\n",
    "def run_tft_experiment(exp_name, exp_type, ds_name, train_data, val_data, test_data,\n",
    "                       train_label, val_label, test_label):\n",
    "    nf_train = prepare_nf_data(train_data)\n",
    "    nf_val = prepare_nf_data(val_data)\n",
    "    nf_test = prepare_nf_data(test_data)\n",
    "\n",
    "    common_ids = (set(nf_train['unique_id'].unique()) &\n",
    "                  set(nf_val['unique_id'].unique()) &\n",
    "                  set(nf_test['unique_id'].unique()))\n",
    "\n",
    "    if len(common_ids) == 0:\n",
    "        print(f\"  {exp_name}: no common series, skipping\")\n",
    "        return\n",
    "\n",
    "    nf_train = nf_train[nf_train['unique_id'].isin(common_ids)].reset_index(drop=True)\n",
    "    nf_val = nf_val[nf_val['unique_id'].isin(common_ids)].reset_index(drop=True)\n",
    "    nf_test = nf_test[nf_test['unique_id'].isin(common_ids)].reset_index(drop=True)\n",
    "\n",
    "    nf_train_val = pd.concat([nf_train, nf_val]).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "\n",
    "    test_horizon = nf_test.groupby('unique_id').size().min()\n",
    "    val_size = min(nf_val.groupby('unique_id').size().min(), test_horizon)\n",
    "    horizon = min(HORIZON, test_horizon)\n",
    "\n",
    "    print(f\"\\n  {exp_name} | h={horizon} | val={val_size} | series={len(common_ids)}\")\n",
    "    print(f\"    Train: {train_label} ({len(train_data)} rows)\")\n",
    "    print(f\"    Val:   {val_label} | Test: {test_label}\")\n",
    "\n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        model = TFT(\n",
    "            h=horizon, input_size=INPUT_SIZE, hidden_size=64, n_head=4,\n",
    "            max_steps=MAX_STEPS, early_stop_patience_steps=-1,\n",
    "            learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE,\n",
    "            scaler_type='robust', random_seed=42,\n",
    "            accelerator=ACCELERATOR, devices=DEVICES,\n",
    "            loss=MAE(), hist_exog_list=ALL_FEATURES, val_check_steps=50,\n",
    "        )\n",
    "\n",
    "        nf = NeuralForecast(models=[model], freq='h')\n",
    "        nf.fit(df=nf_train_val, val_size=val_size)\n",
    "        preds = nf.predict(futr_df=nf_test)\n",
    "        elapsed = time.time() - t0\n",
    "\n",
    "        pred_col = [c for c in preds.columns if c not in ['unique_id', 'ds']][0]\n",
    "        merged = nf_test.merge(preds, on=['unique_id', 'ds'], how='inner')\n",
    "\n",
    "        if len(merged) == 0:\n",
    "            print(f\"    No overlapping predictions\")\n",
    "            return\n",
    "\n",
    "        y_true = merged['y'].values\n",
    "        y_pred = np.clip(merged[pred_col].values, 0, None)\n",
    "        m = calc_metrics(y_true, y_pred, y_true.max())\n",
    "\n",
    "        beach_results = []\n",
    "        for b in merged['unique_id'].unique():\n",
    "            mask = merged['unique_id'] == b\n",
    "            if mask.sum() < 3:\n",
    "                continue\n",
    "            yt = merged.loc[mask, 'y'].values\n",
    "            yp = np.clip(merged.loc[mask, pred_col].values, 0, None)\n",
    "            bm = calc_metrics(yt, yp, yt.max())\n",
    "            bm['beach'] = b\n",
    "            bm['max_count'] = yt.max()\n",
    "            beach_results.append(bm)\n",
    "\n",
    "        beach_df = pd.DataFrame(beach_results)\n",
    "        avg_rel = beach_df['RelMAE'].mean() if len(beach_df) > 0 else np.nan\n",
    "\n",
    "        all_results.append({\n",
    "            'Model': 'TFT', 'Dataset': ds_name, 'Experiment': exp_type,\n",
    "            'Window': exp_name, 'MAE': m['MAE'], 'RMSE': m['RMSE'], 'R2': m['R2'],\n",
    "            'AvgRelMAE': avg_rel, 'Time': elapsed,\n",
    "            'train_period': train_label, 'val_period': val_label, 'test_period': test_label,\n",
    "            'train_rows': len(train_data),\n",
    "        })\n",
    "        all_cv_details.append({\n",
    "            'ds_name': ds_name, 'exp_type': exp_type, 'window': exp_name,\n",
    "            'merged': merged, 'pred_col': pred_col, 'beach_df': beach_df,\n",
    "        })\n",
    "        print(f\"    {elapsed:.0f}s | MAE={m['MAE']:.1f} | RelMAE={avg_rel:.1f}% | R²={m['R2']:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ============================\n",
    "# RUN ALL 3 EXPERIMENT TYPES\n",
    "# ============================\n",
    "for ds_name in ['Full24h', 'Night0', 'NightQ1', 'NightMin']:\n",
    "    chunks = all_chunks[ds_name]\n",
    "\n",
    "    # --- 1. SIMPLE SLIDING (2 chunks train, 1 val, 1 test) ---\n",
    "    print(f\"\\n{'#' * 70}\")\n",
    "    print(f\"# SIMPLE SLIDING — {ds_name}\")\n",
    "    print(f\"{'#' * 70}\")\n",
    "    for w in simple_windows_all[ds_name]:\n",
    "        run_tft_experiment(\n",
    "            exp_name=w['name'], exp_type=\"Simple\",\n",
    "            ds_name=ds_name,\n",
    "            train_data=w['train_data'],\n",
    "            val_data=w['val_data'],\n",
    "            test_data=w['test_data'],\n",
    "            train_label=w['train_label'],\n",
    "            val_label=w['val_label'],\n",
    "            test_label=w['test_label'],\n",
    "        )\n",
    "\n",
    "    # --- 2. EXPANDING ROLLING (growing train) ---\n",
    "    print(f\"\\n{'#' * 70}\")\n",
    "    print(f\"# EXPANDING ROLLING — {ds_name}\")\n",
    "    print(f\"{'#' * 70}\")\n",
    "    for w in rolling_windows[ds_name]:\n",
    "        run_tft_experiment(\n",
    "            exp_name=w['name'], exp_type=\"Expanding\",\n",
    "            ds_name=ds_name,\n",
    "            train_data=w['train_data'],\n",
    "            val_data=w['val_data'],\n",
    "            test_data=w['test_data'],\n",
    "            train_label=w['train_label'],\n",
    "            val_label=w['val_label'],\n",
    "            test_label=w['test_label'],\n",
    "        )\n",
    "\n",
    "    # --- 3. TRAINING SIZE (fixed test, shrinking train) ---\n",
    "    print(f\"\\n{'#' * 70}\")\n",
    "    print(f\"# TRAINING SIZE — {ds_name}\")\n",
    "    print(f\"{'#' * 70}\")\n",
    "    for exp in trainsize_experiments[ds_name]:\n",
    "        run_tft_experiment(\n",
    "            exp_name=f\"TS_{exp['name']}\", exp_type=\"TrainSize\",\n",
    "            ds_name=ds_name,\n",
    "            train_data=exp['train_data'],\n",
    "            val_data=exp['val_data'],\n",
    "            test_data=exp['test_data'],\n",
    "            train_label=exp['train_label'],\n",
    "            val_label=exp['val_label'],\n",
    "            test_label=exp['test_label'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193d890",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e40336",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "save_dir = Path(SAVE_DIR)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_df.to_csv(save_dir / 'tft_chunk_results.csv', index=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ALL RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(results_df[['Dataset', 'Experiment', 'Window', 'train_rows', 'MAE', 'R2', 'AvgRelMAE', 'Time']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be05822",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_type in results_df['Experiment'].unique():\n",
    "    sub = results_df[results_df['Experiment'] == exp_type]\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"{exp_type} — AvgRelMAE (%)\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    pivot = sub.pivot_table(index='Dataset', columns='Window', values='AvgRelMAE')\n",
    "    print(pivot.round(1).to_string())\n",
    "\n",
    "    print(f\"\\n{exp_type} — R²\")\n",
    "    pivot_r2 = sub.pivot_table(index='Dataset', columns='Window', values='R2')\n",
    "    print(pivot_r2.round(3).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3b513",
   "metadata": {},
   "source": [
    "### Experiment Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17960dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results_df) > 0:\n",
    "    exp_types = results_df['Experiment'].unique()\n",
    "    n_exp = len(exp_types)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_exp, 2, figsize=(16, 5 * n_exp))\n",
    "    if n_exp == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for row, exp_type in enumerate(exp_types):\n",
    "        sub = results_df[results_df['Experiment'] == exp_type]\n",
    "        \n",
    "        pivot = sub.pivot_table(index='Dataset', columns='Window', values='AvgRelMAE')\n",
    "        pivot.plot(kind='bar', ax=axes[row, 0], width=0.7, colormap='Set2')\n",
    "        axes[row, 0].set_ylabel('AvgRelMAE (%)')\n",
    "        axes[row, 0].set_title(f'{exp_type} — RelMAE (lower is better)')\n",
    "        axes[row, 0].tick_params(axis='x', rotation=30)\n",
    "        axes[row, 0].legend(title='Window', fontsize=7)\n",
    "        \n",
    "        pivot_r2 = sub.pivot_table(index='Dataset', columns='Window', values='R2')\n",
    "        pivot_r2.plot(kind='bar', ax=axes[row, 1], width=0.7, colormap='Set2')\n",
    "        axes[row, 1].set_ylabel('R²')\n",
    "        axes[row, 1].set_title(f'{exp_type} — R² (higher is better)')\n",
    "        axes[row, 1].tick_params(axis='x', rotation=30)\n",
    "        axes[row, 1].legend(title='Window', fontsize=7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'tft_all_experiments.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# Training size effect\n",
    "ts_res = results_df[results_df['Experiment'] == 'TrainSize']\n",
    "if len(ts_res) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    for ds in ts_res['Dataset'].unique():\n",
    "        sub = ts_res[ts_res['Dataset'] == ds].sort_values('train_rows')\n",
    "        axes[0].plot(sub['train_rows'], sub['AvgRelMAE'], 'o-', label=ds, markersize=6)\n",
    "        axes[1].plot(sub['train_rows'], sub['R2'], 'o-', label=ds, markersize=6)\n",
    "    \n",
    "    axes[0].set_xlabel('Training Rows')\n",
    "    axes[0].set_ylabel('AvgRelMAE (%)')\n",
    "    axes[0].set_title('Effect of Training Size on RelMAE')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].set_xlabel('Training Rows')\n",
    "    axes[1].set_ylabel('R²')\n",
    "    axes[1].set_title('Effect of Training Size on R²')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'tft_trainsize_effect.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# Dataset ranking\n",
    "if len(results_df) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ranking = results_df.groupby(['Dataset', 'Experiment'])['AvgRelMAE'].mean().unstack()\n",
    "    ranking = ranking.loc[ranking.mean(axis=1).sort_values().index]\n",
    "    ranking.plot(kind='barh', ax=ax, width=0.7)\n",
    "    ax.set_xlabel('Mean AvgRelMAE (%)')\n",
    "    ax.set_title('Dataset Strategy Ranking by Experiment Type')\n",
    "    ax.legend(title='Experiment')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'tft_dataset_ranking.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196207d",
   "metadata": {},
   "source": [
    "### Predictions vs Actual — Best Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(all_cv_details) > 0:\n",
    "    best_idx = results_df['AvgRelMAE'].idxmin()\n",
    "    best_row = results_df.iloc[best_idx]\n",
    "    best_detail = all_cv_details[best_idx]\n",
    "    merged = best_detail['merged']\n",
    "    pred_col = best_detail['pred_col']\n",
    "    \n",
    "    beaches = merged['unique_id'].unique()\n",
    "    n_show = min(6, len(beaches))\n",
    "    fig, axes = plt.subplots(n_show, 1, figsize=(16, 3 * n_show), sharex=False)\n",
    "    if n_show == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, beach in zip(axes, beaches[:n_show]):\n",
    "        sub = merged[merged['unique_id'] == beach].sort_values('ds')\n",
    "        ax.plot(sub['ds'], sub['y'], label='Actual', color='steelblue', linewidth=1)\n",
    "        ax.plot(sub['ds'], np.clip(sub[pred_col], 0, None), label='TFT', color='coral', linewidth=1, alpha=0.8)\n",
    "        ax.fill_between(sub['ds'], sub['y'], np.clip(sub[pred_col], 0, None), alpha=0.15, color='red')\n",
    "        \n",
    "        mae = mean_absolute_error(sub['y'], np.clip(sub[pred_col], 0, None))\n",
    "        r2 = r2_score(sub['y'], np.clip(sub[pred_col], 0, None)) if len(sub) > 1 else 0\n",
    "        ax.set_title(f'{beach[:35]} | MAE={mae:.1f} | R²={r2:.3f}', fontsize=9, loc='left')\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "        ax.set_ylabel('Count')\n",
    "    \n",
    "    axes[-1].set_xlabel('Date')\n",
    "    plt.suptitle(f\"Best: {best_row['Dataset']} {best_row['Window']} | RelMAE={best_row['AvgRelMAE']:.1f}%\", fontsize=13, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'tft_predictions_best.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ac3c9",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ac1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(all_cv_details) > 0:\n",
    "    best_idx = results_df['AvgRelMAE'].idxmin()\n",
    "    best_detail = all_cv_details[best_idx]\n",
    "    merged = best_detail['merged']\n",
    "    pred_col = best_detail['pred_col']\n",
    "    \n",
    "    errors = merged['y'].values - np.clip(merged[pred_col].values, 0, None)\n",
    "    abs_errors = np.abs(errors)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    axes[0,0].hist(errors, bins=80, color='steelblue', alpha=0.7, edgecolor='white')\n",
    "    axes[0,0].axvline(0, color='red', linestyle='--')\n",
    "    axes[0,0].axvline(errors.mean(), color='orange', linestyle='--', label=f'Bias={errors.mean():.1f}')\n",
    "    axes[0,0].set_xlabel('Error')\n",
    "    axes[0,0].set_title('Error Distribution')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    axes[0,1].scatter(merged['y'], np.clip(merged[pred_col], 0, None), s=2, alpha=0.3, color='steelblue')\n",
    "    mx = max(merged['y'].max(), merged[pred_col].max())\n",
    "    axes[0,1].plot([0, mx], [0, mx], 'r--', linewidth=1)\n",
    "    axes[0,1].set_xlabel('Actual')\n",
    "    axes[0,1].set_ylabel('Predicted')\n",
    "    axes[0,1].set_title('Actual vs Predicted')\n",
    "    \n",
    "    merged_t = merged.copy()\n",
    "    merged_t['hour'] = merged_t['ds'].dt.hour\n",
    "    merged_t['abs_err'] = abs_errors\n",
    "    hourly = merged_t.groupby('hour')['abs_err'].mean()\n",
    "    axes[1,0].bar(hourly.index, hourly.values, color='coral', alpha=0.7)\n",
    "    axes[1,0].set_xlabel('Hour')\n",
    "    axes[1,0].set_ylabel('MAE')\n",
    "    axes[1,0].set_title('Error by Hour')\n",
    "    \n",
    "    bdf = best_detail['beach_df'].sort_values('RelMAE')\n",
    "    colors = ['green' if v < 30 else 'steelblue' if v < 60 else 'coral' for v in bdf['RelMAE']]\n",
    "    axes[1,1].barh(range(len(bdf)), bdf['RelMAE'], color=colors, alpha=0.8)\n",
    "    axes[1,1].set_yticks(range(len(bdf)))\n",
    "    axes[1,1].set_yticklabels([b[:30] for b in bdf['beach']], fontsize=6)\n",
    "    axes[1,1].set_xlabel('RelMAE (%)')\n",
    "    axes[1,1].set_title('Per-Beach RelMAE')\n",
    "    axes[1,1].invert_yaxis()\n",
    "    \n",
    "    plt.suptitle('Error Analysis — Best Window', fontsize=13, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / 'tft_error_analysis.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Bias: {errors.mean():.1f} | MAE: {abs_errors.mean():.1f} | Median AE: {np.median(abs_errors):.1f}\")\n",
    "    print(f\"90th pct error: {np.percentile(abs_errors, 90):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141346be",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n--- Best per Experiment Type ---\")\n",
    "for exp_type in results_df['Experiment'].unique():\n",
    "    sub = results_df[results_df['Experiment'] == exp_type]\n",
    "    best = sub.loc[sub['AvgRelMAE'].idxmin()]\n",
    "    print(f\"  {exp_type:12s} | {best['Dataset']:10s} | {best['Window']} \"\n",
    "          f\"| RelMAE={best['AvgRelMAE']:.1f}% | R²={best['R2']:.3f}\")\n",
    "\n",
    "print(\"\\n--- Best per Dataset (across all experiments) ---\")\n",
    "for ds in results_df['Dataset'].unique():\n",
    "    sub = results_df[results_df['Dataset'] == ds]\n",
    "    best = sub.loc[sub['AvgRelMAE'].idxmin()]\n",
    "    print(f\"  {ds:10s} | {best['Experiment']:12s} {best['Window']} \"\n",
    "          f\"| RelMAE={best['AvgRelMAE']:.1f}% | R²={best['R2']:.3f}\")\n",
    "\n",
    "print(\"\\n--- Stability (CV% = std/mean across windows) ---\")\n",
    "for exp_type in results_df['Experiment'].unique():\n",
    "    sub = results_df[results_df['Experiment'] == exp_type]\n",
    "    stab = sub.groupby('Dataset')['AvgRelMAE'].agg(['mean', 'std'])\n",
    "    stab['cv%'] = (stab['std'] / stab['mean'] * 100).round(1)\n",
    "    print(f\"\\n  {exp_type}:\")\n",
    "    print(stab.sort_values('mean').round(1).to_string())\n",
    "\n",
    "print(\"\\n--- Training Size Effect (same test period) ---\")\n",
    "ts_res = results_df[results_df['Experiment'] == 'TrainSize']\n",
    "if len(ts_res) > 0:\n",
    "    for ds in ts_res['Dataset'].unique():\n",
    "        sub = ts_res[ts_res['Dataset'] == ds].sort_values('train_rows')\n",
    "        print(f\"\\n  {ds}:\")\n",
    "        for _, row in sub.iterrows():\n",
    "            print(f\"    {row['Window']:8s} ({row['train_rows']:5.0f} rows) | RelMAE={row['AvgRelMAE']:.1f}% | R²={row['R2']:.3f}\")\n",
    "\n",
    "overall = results_df.loc[results_df['AvgRelMAE'].idxmin()]\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"OVERALL BEST: {overall['Experiment']} | {overall['Dataset']} | {overall['Window']}\")\n",
    "print(f\"  Train: {overall['train_period']}\")\n",
    "print(f\"  Test:  {overall['test_period']}\")\n",
    "print(f\"  RelMAE={overall['AvgRelMAE']:.1f}% | R²={overall['R2']:.3f} | MAE={overall['MAE']:.1f}\")\n",
    "print(f\"{'=' * 70}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
